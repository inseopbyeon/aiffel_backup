{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81970e3b",
   "metadata": {},
   "source": [
    "# ViT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a19056",
   "metadata": {},
   "source": [
    "기본적인 이미지 분류를 위한 VGG 모델 구조를 표현한 그림이 있습니다.\n",
    "((Batch,) Height, Width, Channel) 형태의 텐서로 이루어진 이미지가 여러 레이어를 거치며 조금씩 변형되는 모습을 보여주고 있습니다.\n",
    "\n",
    "모델 후반부의 분류기 구조를 자세하게 살펴보죠.\n",
    "클래스 분류를 수행하기 직전의 레이어까지, 각 노드의 출력에 해당하는 여러 개의 스칼라 값들이 나열되어있군요.\n",
    "우리에게 익숙한 밀집 벡터 형태로 변환할 수 있지 않을까? 라는 호기심이 자연스레 머릿속을 스쳐 지나갑니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534fb37",
   "metadata": {},
   "source": [
    "자연어 처리(Natural Language Processing, NLP) 분야에서는 수많은 시퀀스 형태의 임베딩(밀집 벡터)도 척척 다룰수 있는 어텐션 메커니즘(Attention mechanism)이 이미 급부상하고 있었습니다.\n",
    "\n",
    "입력 데이터의 길이에 영향을 적게 받고, 사뭇 미묘하고 복잡해보이는 표현들도 세밀하게 구분하는 능력을 보여준 어텐션 메커니즘은 곧 트랜스포머(Transformer)라는 뛰어난 모델로 꽃을 피웁니다. NLP 에서 이미 독보적인 성능을 보여준 트랜스포머는 어쩌면 컴퓨터 비전(Computer Vision, CV)으로 영역을 넓혀 Convolution 기반의 레이어 구조들을 대체하면서 혁신적인 성능을 보일지도 모르겠군요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346ae7f",
   "metadata": {},
   "source": [
    "가장 단순한 Image classification task부터 시작해봅니다.\n",
    "컴퓨터 비전 분야에서 트랜스포머를 적용하려는 여러 번의 시도는 어찌보면 굉장히 단순한 형태로 시작되었습니다.\n",
    "\n",
    "트랜스포머가 보여줬던 특출난 장점 중에는 1) 입력처리가 유연하다, 2) 스케일 가능한 아키텍쳐를 가지고 있다, 3) 병렬 처리에 유리하다 등이 있습니다.\n",
    "아직 트랜스포머에 익숙하지 않으실 분들을 위해, 위 특성들을 구현할 수 있는 구성요소들을 간단하게 살펴볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb50f6c",
   "metadata": {},
   "source": [
    "#### 1) 입력처리가 유연하다\n",
    "\n",
    "어텐션을 활용하기 위해서는 입력 데이터에서 단어(텍스트형)들을 Token (숫자형) 으로 인코딩하고, Scalar 형태의 토큰들을 Vector 형태의 Embedding 으로 변환하는 작업을 거칩니다. 이를 통해 의미의 경계가 뚜렷하지 않은 아주 많은 종류의 단어(토큰)들도 상대적으로 적은 차원 형식을 통해 구분하여 활용할 수 있습니다.\n",
    "\n",
    "트랜스포머를 제안한 논문 에서는, 입력 데이터 시퀀스 안에서 각 단어들의 위치를 서로 구별하기 위하여 단어의 임베딩에 Positional encoding 을 더해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd98398",
   "metadata": {},
   "source": [
    "#### 2) 스케일 가능한 아키텍쳐\n",
    "\n",
    "트랜스포머의 주요 구조는 어텐션 레이어를 조합한 Encoder 와 Decoder 단위 구성체(Unit)로 이루어져있습니다. 이러한 유닛 구조의 장점으로는 몇 개의 유닛을 쌓느냐(stackable)에 따라 모델이 처리할 수 있는 정보의 스케일을 손쉽게 조정할 수 있다는 점이 있습니다.\n",
    "\n",
    "그림에서 관찰할 수 있듯이, 통상적으로 인코더 역할의 유닛은 입력 데이터로부터 특성들을 추출하여 정제하는 역할을 하고, 디코더 유닛은 인코더에서 나온 정보와 이전 단계의 출력 함께 전달받아, 새로운 결과물을 만들어내는 기능을 한다고 알려져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c63ea",
   "metadata": {},
   "source": [
    "#### 3) 병렬 처리에 유리하다\n",
    "\n",
    "트랜스포머로 입력된 임베딩은 또 다른 형태의 행렬들로 변환되어 각각 어텐션 계산 과정에 활용됩니다. Self-attention 계산을 위해 필요한 요소로 Key, Query, Value 가 있으며, 각 변환 과정에서는 적절한 크기의 가중치 행렬들이 함께 계산과정에 참여하게 됩니다.\n",
    "\n",
    "트랜스포머를 이루는 대부분의 요소들이 행렬 형태로 전달되기 때문에, 학습 과정에서 단순한 행렬 연산을 반복하면서 병렬로 연산을 처리하기에 용이하다는 특징을 가지게 됩니다. 이전보다 상대적으로 굉장히 많은 양의 데이터를 효율적으로 학습하게 되었으며, 특히 모델과 데이터 사이에 연결된 내재적인 의미들을 확장하여 인식하는 데 빼어난 성능을 보이고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fdd75",
   "metadata": {},
   "source": [
    "#### Transformer 가 이미지를 구분하기 위해서는?\n",
    "\n",
    "이렇게 성능이 뛰어난 트랜스포머에 자연어가 아닌 이미지 형식을 입력하기 위해서는 어떻게 해야할까요?\n",
    "\n",
    "**Vision Transformer , 줄여서 ViT** 는 이 과정을 간결하고도 성공적으로 수행해 낸 논문으로 평가됩니다. 특히 트랜스포머의 기존 내부 구조를 거의 변형하지 않고도 이미지 데이터를 입력 받을 수 있었다는 점에서 주된 의의를 갖습니다.\n",
    "\n",
    "논문의 그림에서 제시된 구조를 살펴볼 때, 입력된 이미지는 특정한 변환작업을 거쳐 트랜스포머 인코더로 들어갑니다. 입력 데이터에서 패턴을 추출하는 역할의 트랜스포머 인코더 부분을 가져와 ViT 메인 구조로 활용하는 것을 확인할 수 있습니다. 인코더에서 정제되어 나온 출력 중 일부는 간단한 신경망 분류기에 넣어 최종적으로 클래스 분류 작업을 수행하게 됩니다.\n",
    "\n",
    "이러한 과정을 준비하기 위해서, **기존 트랜스포머에 사용되던 세 가지의 요소를 이미지라는 데이터 특성에 맞추어 변형**해야 합니다.\n",
    "\n",
    "* 텍스트 토큰을 임베딩으로 변환 **->> Patch**\n",
    "* 클래스 정보를 담은 특수 토큰 **->> Class Token**\n",
    "*이미지 형식에 맞는 위치 정보 **->> Positional Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da3c73",
   "metadata": {},
   "source": [
    "#### 이미지를 Patch 로 잘게 쪼개자!\n",
    "그림의 왼쪽 아래, 모델에 입력된 건물 이미지가 보이네요.\n",
    "\n",
    "**먼저 입력 사이즈의 이미지를 더 작은 단위의 구성 요소인 패치 Patch로 나눕니다. 이미지로부터 작게 나눠진 패치는 아직 행렬 형태이기 때문에, 시퀀스 데이터와 유사한 벡터 형태로 나열해주어야 합니다.** 왼쪽 위 시작점의 패치부터 순서대로 하나씩 정렬한 후, 데이터를 벡터 형태로 만드는 Flatten 작업을 거칩니다.\n",
    "\n",
    "하나의 패치는 전체 이미지에서 부분적인 정보만을 담고 있지만, 트랜스포머모델은 어텐션 계산 과정을 통해 각 패치들을 서로 비교하면서, 전체 이미지가 담고 있는 특성을 차근차근 파악해 나가게 될 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c002d3",
   "metadata": {},
   "source": [
    "#### 어디에 있던 Patch 였지?\n",
    "Flatten 처리되어 벡터로 변형된 각 패치들은 Linear 연산을 통해 지정된 형태의 Embedding 으로 변환됩니다.\n",
    "\n",
    "**시퀀스 형태로 정렬된 임베딩 가장 앞 부분에 클래스 예측을 위한 Class token embedding을 추가해줍니다. 데이터의 Label 로부터 만들어진 이 토큰은 이미지와 함께 입력되는 클래스 정보를 담고있으며, 각기 다른 입력 데이터들을 구분하고 연관지어주는 열쇠로 작용하게 됩니다.**\n",
    "클래스 토큰이 포함된 패치 임베딩에 **지정된 형식의 Positional embedding 을 더해주면, 원본 이미지에서 패치들이 어느 위치에 있었는지에 대한 정보도 놓치지 않고 학습 과정에\n",
    "서 활용할 수 있게 됩니다.**\n",
    "\n",
    "아래 링크로 들어가 마우스 커서를 이미지 위에 올려놓으면, 선택된 패치와 연관성이 높은 패치의 활성도를 시각화해놓은 자료를 관찰하실 수 있습니다. 레이어 깊이에 따라 실제 모델의 계산 결과를 관찰하는 것도 좋은 생각 포인트가 되겠죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43979916",
   "metadata": {},
   "source": [
    "#### ViT 의 성능이 궁금하세요?\n",
    "컴퓨터 비전에 적용된 ViT 는 어떤 장점과 단점을 보여주고 있을까요?\n",
    "또, 기존 CV 분야에서 막대한 기여를 해온 Convolution layer 기반 모델들과 비교했을때, 어떤 부분에서 차이점을 보여주고 있는걸까요?\n",
    "이렇게 뛰어난 ViT에서 더 발전해나갈 부분이 있을까요?\n",
    "하나씩 짚어가며 살펴봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe424a",
   "metadata": {},
   "source": [
    "ViT의 구성을 간략하게 요약해보자면, 이미지의 형태를 변경하는 임베딩 전처리 과정을 네트워크 앞부분에 덧붙이고, 이미지 해석을 위한 백본 네트워크로 트랜스포머를 활용한 것으로 볼 수 있습니다. 이 과정에서 입출력 데이터의 형태가 동일한 트랜스포머의 특성을 거의 동일하게 유지하였으며, 결과적으로 트랜스포머의 뛰어난 확장성을 유지할 수 있었습니다.\n",
    "\n",
    "모듈식으로 이루어진 ViT 의 구성요소들은 내부 구조를 부분적으로 변경하고자할 때 아주 편리하며, 작업자가 설정한 문제 정의에 맞추어 자유롭게 스케일을 조정할 수 있다는 커다란 이점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd736aaf",
   "metadata": {},
   "source": [
    "그렇다면 트랜스포머를 기반으로한 ViT 는 단점이 존재하지 않는 완벽한 모델이 될 수 있을까요?\n",
    "\n",
    "**CNN, ViT 등 여러 학습 알고리즘을 비교하는 특성 중 하나로, 귀납적 편향 문제 Problem of inductive bias 이라는 단어를 사용하곤 합니다.**\n",
    "\n",
    "여러 학습 알고리즘들 사이에 어떤 차이가 나타나는지 한번 검색해볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38215a02",
   "metadata": {},
   "source": [
    "> 귀납적 편향이란 학습 알고리즘이 일반적인 상황에 적응하기 위해 사용하는 가정을 의미합니다. 이러한 가정은 모델이 학습하는 데이터의 특성에 따라 선택됩니다. 예를 들어, RNN은 시간적인 순서가 중요하다는 가정을 가지고 있습니다. CNN은 이미지의 지역적인 특징이 중요하다는 가정을 가지고 있습니다. ViT는 이미지의 전역적인 관계가 중요하다는 가정을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73009b",
   "metadata": {},
   "source": [
    "위 그림에서 알 수 있듯이, 기존의 CNN 모델들은 지역적인 특성을 검출하는 기능을 바탕으로 명시적이고 직관적인 Explicit 특성을 가진 반면, ViT 는 이미지의 전역적인 관계성을 파악함으로써 내재적인 메시지나 추상적이고 감정적인 의미 등 Implicit 한 특성이 두드러진다고 볼 수 있습니다. 엄밀히 말해 귀납적 편향은 단점이라기보다 각 알고리즘의 특성이라고 표현해야겠지만, 우리가 적용하고자 하는 문제의 정의에 맞춰 충분히 깊이 고민해봐야할 점인 것은 분명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc11daa",
   "metadata": {},
   "source": [
    "#### Let's Swin! 앞으로 한 발짝 더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9c8f1",
   "metadata": {},
   "source": [
    "![Swin transformer](./Swin_transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f25fc",
   "metadata": {},
   "source": [
    "2021 년 발표된 ViT는 이후 Foundation 수준의 Backbone 으로서 인정받기 시작하면서 다양한 방식으로 널리 활용되기 시작합니다. 그 중에서도 뛰어난 성능 향상을 보이며 주목받은 모델로 **Swin** transformer가 있습니다. **S**hifted **win**dows 의 약어로도 알려진 Swin transformer는, 주로 Implicit 한 특성을 지닌 ViT 에서 출발해 더 다양한 Explicit 특성을 가미하기 위해 여러 장치들을 적용하였습니다.\n",
    "\n",
    "Swin trasnformer의 저자는 CV 분야에서 트랜스포머를 적용하기 어렵게 만드는 두 가지 차이점으로, 1) 이미지 내에서 시각적 대상의 크기가 다양하게 변한다는 점과 2) 이미지를 효과적으로 분석하기 위해 높은 픽셀 해상도가 필요하다는 점을 강조하였습니다. 이를 해결하기위해 feature pyramid network 를 연상케하는 계층적(hierarchical)인 window 구조를 적용하였으며, 각 윈도우의 연관성을 다양하게 유지하기 위해 윈도우를 변형하여 모델에 입력하는 cyclic shift방식을 추가하였습니다.\n",
    "\n",
    "각 장치들이 어떤 방식으로 작동하는지 상세한 과정들에 대해 살펴보진 않겠지만, 이전 CV 분야에 있었던 굵직한 모델들이 발전해온 흐름과 ViT 이후 모델들의 변화를 비교하여 연결해본다면, 컴퓨터 비전 분야에서 해결하고자 하는 주요한 쟁점들을 떠올리는데 효과적인 공부가 될 수 있겠네요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a8ff3",
   "metadata": {},
   "source": [
    "# Diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d520a",
   "metadata": {},
   "source": [
    "### 이미지 생성 모델의 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffdc1dd",
   "metadata": {},
   "source": [
    "![image generation models 1](./image_generation_models_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd62cf",
   "metadata": {},
   "source": [
    "컴퓨터 비전 분야에서 이미지를 활용한 생성 모델을 구성하는 방식은, 위 그림처럼 크게 세 분야로 나눠 볼 수 있습니다.\n",
    "\n",
    "1. Generative Adversarial Network (GAN)\n",
    "2. Variational AutoEncoder (VAE)\n",
    "3. Diffusion model\n",
    "\n",
    "위 방법론들이 탄생하게된 계기나, 아이디어가 발전된 시기에서 차이가 나지만,\n",
    "각 모델들이 보여주는 다양한 퍼포먼스 특징들은 영역 별로 꽤나 분명하게 나뉘어있기도 합니다.\n",
    "동시에, 아래 그림에서 같이 모델들이 구조적으로 서로 공유하고 있는 컨셉도 엿볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e956a60",
   "metadata": {},
   "source": [
    "![image generation models 2](./image_generation_models_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33702faa",
   "metadata": {},
   "source": [
    "### 멀쩡한 데이터에 노이즈를 섞어 보았는데요?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177c547",
   "metadata": {},
   "source": [
    "딥러닝 생성분야에서 최근에 주목받고있는 디퓨전 모델 은, 기존의 강자였던 GAN 과 비교했을 때 다음과 같은 몇 가지 장점을 보입니다.\n",
    "\n",
    "1. 디퓨전 모델은 GAN 보다 더 안정적이고 빠르게 학습됩니다.\n",
    "2. 디퓨전 모델은 GAN 보다 더 사실적이고 고품질의 이미지를 생성할 수 있습니다.\n",
    "3. 디퓨전 모델은 다양한 특성이 함께 담겨있는 이미지를 생성할 수 있습니다.\n",
    "\n",
    "디퓨전 모델은 완전한 노이즈로부터 시작하여 이를 점차적으로 제거함으로써 새로운 이미지를 생성합니다.\n",
    "이미지 생성을 위해 디퓨전 모델이 학습하는 과정은 크게 **diffusion 과 denoising process**, 두 부분으로 나누어 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa46a19",
   "metadata": {},
   "source": [
    "먼저, **forward process 라고도 불리는 diffusion process** 입니다. 디퓨전 과정은 원본 이미지와 노이즈를 활용해 학습에 사용될 데이터를 만드는 과정입니다.\n",
    "\n",
    "일정한 간격의 스텝 t 에 따라 원본 이미지에서부터 점차적으로 노이즈를 더해 섞어주면서, 학습하려는 이미지와 노이즈 사이에 다수의 중간 단계를 만들어줍니다.\n",
    "**일반적으로 가우시안 분포를 활용하여 노이즈를 생성할 수 있고, 동일한 과정을 다수 반복하면서 점진적으로 이미지를 변형(large number of small perturbation) 해가는 과정**이라고 이야기할 수 있습니다.\n",
    "중간 단계의 스텝 수는 사용자가 직접 조정할 수 있는 하이퍼파라미터이며, 그림에서도 관찰할 수 있듯이 여러 가지 diffusion scheduling 기법을 활용하면 원본 이미지의 특성이 어느 스텝 시점까지 유지될 수 있을지도 조정이 가능합니다.\n",
    "디퓨전 과정은 하나의 데이터와 단일 프로세스를 이용하여, 동일한 내재적 특성을 공유하는 서로 다른 입력 데이터(latent variables)를 생산할 수 있다는 특징을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7121e",
   "metadata": {},
   "source": [
    "다음은 **backward process 또는 denoising process** 부분입니다.\n",
    "노이즈 제거 모델은 입력 데이터안에서 특정 분포의 노이즈를 제거하며 점차 더 선명한 이미지를 출력하는 작업을 반복하게 됩니다.\n",
    "\n",
    "위 그림과 같이 앞서 디퓨전 과정을 통해 제작한 t 와 t-1 시점의 노이즈가 포함되어 있는 이미지 데이터를 준비합니다. 다음으로 t 스텝의 이미지를 입력받아 노이즈의 분포를 예측하고 제거할 noise predictor 를 설정해줍니다. 이때 모델은 원본 이미지에 연결되어있던 text embedding 을 참고하여, 노이즈를 제거하고 난 후 출력 이미지에 남겨둘 형상 정보들을 추정할 수 있게 됩니다.\n",
    "이러한 단일 과정을 거치면서 t-1 스텝의 이미지는 공통된 내재적 특성을 유지할 수 있고, 이미지 안에서 표현되어야할 세부 정보들을 발전시켜 나갈 수 있게 됩니다. t 와 t-1 시점의 입력 이미지들은 스텝 수 설정에 따라 충분히 학습을 거쳐 예측이 가능할 만큼 작은 차이들을 지니게 됩니다.\n",
    "전체 학습 과정을 반복하고나면 디노이징 모델이 랜덤한 노이즈부터 사전 조건에 맞춰 새로운 형태의 선명한 이미지들을 완성할 수 있겠죠!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc06e4d",
   "metadata": {},
   "source": [
    "디퓨전 모델의 주요 목적은 Loss 함수 설정에서 엿볼 수 있습니다.\n",
    "아주 다양한 종류의 디퓨전 모델이 있지만, 기존의 생성모델들과 차이점은 역시 노이즈 제거 과정이 차지하는 역할이 크다는 점입니다.\n",
    "최종적으로 생성된 이미지와의 차이도 중요하지만, 디노이징 과정에서 우리가 타겟으로 삼은 데이터 분포를 잘 따라가고 있는지 확인하는 과정이 중요해보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e861bc",
   "metadata": {},
   "source": [
    "### Latent, 그 오묘한 세계로!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353aeda",
   "metadata": {},
   "source": [
    "내재적 표현 Latent representation 을 활용하면 데이터가 담고 있는 특성들의 유사성을 검토할 수 있고 데이터 사이의 연관성을 더욱 간결하게 표현할 수 있을 것 같습니다.\n",
    "\n",
    "딥러닝 모델에서 내재적 표현이란?\n",
    "> 가중치를 시각화하여 모델이 데이터를 어떻게 인식하고 있는지 이해합니다.\n",
    "활성화 함수를 분석하여 모델이 내재적 표현을 생성하는 방법을 이해합니다.\n",
    "가중치는 딥러닝 모델이 데이터에서 학습한 내재적 표현을 나타냅니다. 가중치를 분석하면 모델이 데이터를 어떻게 인식하고 있는지 이해할 수 있습니다.\n",
    "활성화 함수는 딥러닝 모델의 층에서 계산되는 함수입니다. 활성화 함수는 가중치를 통해 들어오는 정보를 처리하고 내재적 표현을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04096cee",
   "metadata": {},
   "source": [
    " 우리는 모델이 데이터를 어떻게 해석하고 있는지 관찰하면서 내재적 표현을 확인할 수 있습니다.\n",
    "하지만 너무 많은 특성을 동시에 담고있는 의미적 표현은, 관찰자가 데이터들을 직관적으로 인식하기 어렵게 만들 수도 있습니다.\n",
    "이를 위해 **우리는 데이터의 차원을 조금 낮추어, 데이터를 구별하는데 주효한 특성들만 남도록 모델의 구조를 설정할 수 있습니다.\n",
    "또한 밀집 벡터 형식의 임베딩을 활용하면 연속적인 차원안에 우리가 원하는 데이터들을 동시에 나열하기에 용이합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78fd20",
   "metadata": {},
   "source": [
    "위의 그림들은, 두 데이터의 간 차이를 선형적으로 채워나가는 상황에서 각각 이미지 공간과 내재 공간을 활용하는 방법을 비교하고 있습니다.\n",
    "\n",
    "이미지 공간에서 선형적으로 보간을 수행할 때는 두 가지의 형상이 서로 겹쳐진 채로 동시에 존재하며 보이지만,\n",
    "내재 벡터를 활용할 경우에 '손글씨로 적은 숫자' 라는 이미지적 특성을 유지한 채로 더 합리적이고 분명한 결과가 출력되는 것을 볼 수 있습니다(다만, 내재 벡터로부터 Reconstruction을 수행할 모델을 학습해야하는 추가 과정이 생략되었습니다).\n",
    "또한 벡터 표현들을 활용할 경우, 여러 특성들을 수치적으로 연산하여 간접적으로 조정할 수도 있겠군요.\n",
    "\n",
    "이러한 작용들은 훨씬 높은 차원의 표현(이미지에서의 형상 정보 등)을 더 자연스럽게 변형시키기 위해, 우리가 어떤 표현과 방법으로 접근해야 하는 지에 대해 중요한 영감을 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b881fc",
   "metadata": {},
   "source": [
    "여기까지 내재적 표현에 대해 이해한 상태에서, 우리가 다뤄야할 모델 이야기로 돌아가 볼까요!\n",
    "\n",
    "초기 디퓨전 모델은 고해상도의 이미지 데이터를 다루면서 동시에 아주 많은 스텝으로 나누어진 데이터를 활용하다 보니, 줄곧 학습 시간 등 연산에 필요한 자원량이 실용적이지 못하다는 점을 지적받아 왔습니다.\n",
    "이렇듯 과도한 리소스가 필요한 디퓨전 모델의 접근성을 향상시키기 위해, representational space 를 활용한 Latent Diffusion Model(LDM) 이 제시되었고, 곧 엄청난 주목을 받기 시작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddffef7",
   "metadata": {},
   "source": [
    "### 두둥 그리고 Stable Diffusion!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83068397",
   "metadata": {},
   "source": [
    "Stable diffusion 은 어떤 종류의 데이터를 입력으로 활용할까요?\n",
    "> 원본 이미지는 임베딩 형태로 입력됩니다. 텍스트 형태의 그림 설명은 text encoder 를 거쳐 활용됩니다. 노이즈로부터 만들어진 patch 도 보이는군요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ced50",
   "metadata": {},
   "source": [
    "1. autoencoder 로 입력된 pixel Image 를 latent variable(z) 로 압축합니다.\n",
    "2. 저차원으로 압축된 latent space 수준에서 noise 를 첨가하는 diffusion process 수행합니다.\n",
    "3. CLIP 을 이용하여 image 와 text 를 같은 embedding 으로 결합합니다.\n",
    "4. 저차원의 latent variable 을 이용하여 빠르게 denoising diffusion 과정을 수행하면서 일정 수준까지 노이즈를 제거합니다.\n",
    "5. 최종적으로 예측한 latent variable 을 autoencoder 의 디코더로 재건하여 원본 해상도의 pixel image 로 다시 복원합니다.\n",
    "> SD 모델은 학습과정에서 Image, text 와 noise 를 입력받아, 노이즈를 단계적으로 제거하면서 이미지를 복원하는 과정을 배우게 되고,\n",
    "추론과정에서는 입력 이미지 없이도, text 등의 조건과 noise 만으로 새로운 Image 를 생성하는 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aebafb",
   "metadata": {},
   "source": [
    "### Stable diffusion 실습(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f15d65",
   "metadata": {},
   "source": [
    "#### Latent 의 매력에 흠뻑 빠져봅시다!\n",
    "Stable diffusion 은 **Latent Diffusion Model(LDM)** 의 개념을 적극적으로 도입하면서, 모델의 연산 효율성과 생성 결과의 안정성을 모두 향상시킨 모델로 평가받습니다.\n",
    "Latent space 수준에서 조정되는 요소들이, 실제로 SD 모델의 내부에 어떤 영향을 미치는지 살펴봅시다.\n",
    "\n",
    "SD 모델 구조에서 LDM 이란 아래의 구성 요소를 조합하는 과정을 통해 구현할 수 있습니다.\n",
    "\n",
    "* Autoencoder\n",
    "* CLIP embedding generator\n",
    "* Unet with attention\n",
    "\n",
    "우리는 Autoencoder 구조를 통해서 pixel space의 이미지가 더 적은 차원의 latent space 안에 머물도록 변환할 수 있습니다.\n",
    "SD 모델은 이 잠재 공간 안에 각 이미지들의 특성이 manifold 구조를 형성할 수 있도록 학습합니다.\n",
    "매니폴드 구조 안의 특정 지점으로부터 임베딩을 추출하는 작업을 sampling이라고 지칭하며,\n",
    "임베딩으로부터 사람이 시각적으로 인지할 수 있는 픽셀 이미지를 복원하는 작업을 decoding이라고 부릅니다.\n",
    "SD 모델은 미리 학습된 오토인코더의 디코더를 가져와 추정된 잠재 변수로부터 새로운 이미지를 생성합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bbb68b",
   "metadata": {},
   "source": [
    "잠재 공간의 매니폴드는 연속적이면서, 보간적인 성질을 지닙니다.\n",
    "\n",
    "* 연속성: 매니폴드 안에서 조금씩 이동하면, 해당 생성 이미지도 이에 맞춰 조금씩 변화합니다\n",
    "* 보간성: 매니폴드 안에 특정한 두 점 A, B 를 상상해봅시다. A와 B 사이의 중간 지점은 매니폴드 내의 경로를 통해서 A부터 B로 이동할 수 있습니다. 이 중간점들은 모두 이미지를 생성하는데 유효합니다.\n",
    "\n",
    "SD 모델은 최종적으로 **두 종류의 잠재 공간을 활용**하게 됩니다. 하나는 인코더를 통해 얻은 임베딩으로 학습한 이미지적 표현들이 담긴 공간이며,\n",
    "다른 하나는 사전에 학습된 후 이미지와 함께 미세조정을 거친 프롬프트 잠재 공간입니다.\n",
    "이런 사실을 볼 때, SD 모델은 이미지 모델이면서 동시에 자연어 모델이라고 부를 수 있겠습니다.\n",
    "\n",
    "자 그러면 본격적으로 SD 모델의 잠재 공간을 탐험해 보겠습니다.\n",
    "일단 빠르게 준비 과정을 거쳐야겠죠! 먼저 필요한 환경요소를 설치해볼까요!\n",
    "이번 스텝에서 사용할 모델은 KerasCV 에 사전학습된 Stable diffusion입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2d173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5d9f33",
   "metadata": {},
   "source": [
    "텍스트 프롬프트 사이사이를 관찰해볼까요?\n",
    "두 가지 숫자 사이에는 쉽게 중간값을 갖는 지점을 떠올려볼 수 있습니다.\n",
    "단어와 단어의 사이는 어떤가요? 서로 의미에서 차이가 나는 두 단어 사이에 또 다른 단어가 존재하지않을까요?\n",
    "문장과 문장의 경우엔 어떻게 표현할 수 있을까요? 유연한 구조를 가지면서 중간 정도의 의미를 담고있는 문장을 어떻게 구성하면 좋을까요?\n",
    "\n",
    "먼저, 두 가지의 프롬프트를 설정해줍니다. 이 문장들은 각각 모델 내부의 인코더 구조로 들어가 임베딩 형태로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01dba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3e0a07",
   "metadata": {},
   "source": [
    "움직이는 그림으로 구성해놓으니 지역적인 이미지 특징들이 점차 변해가는 것이 잘 보입니다.\n",
    "단계를 더 잘게 나누어 보면 훨씬 부드럽게 형상이 변할 수 있을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0e1177",
   "metadata": {},
   "source": [
    "시간 간격으로 변화를 관찰했다면, 이번엔 일정 거리만큼 떨어진 임베딩들 사이를 비교해봅시다.\n",
    "4 개의 프롬프트를 각 코너에 배치하고, 극단의 사이를 선형적으로 채워보겠습니다.\n",
    "어떤 특징들을 발견할 수 있을 지 궁금하네요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c49a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d8134f",
   "metadata": {},
   "source": [
    "너무 정적인 변화만 관찰하다보니 심심하게 느껴질 수 있겠네요.\n",
    "diffusion_noise 인자를 함수 입력에서 제외하면, 노이즈가 고정되지 않고 더 다양해지면서 출력 결과도 달라지는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b244f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6083465",
   "metadata": {},
   "source": [
    "### Stable diffusion 실습(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4e3f0",
   "metadata": {},
   "source": [
    "Stable diffusion 모델은 커다란 모델이다보니 파라미터 전체를 한꺼번에 학습하기 위해서는 여전히 높은 하드웨어 사양을 요구합니다. 따라서 파라미터를 일부분만 갱신하더라도 더 가볍고 효과적으로 미세조정하는 방법이 다양하게 개발되고있습니다.\n",
    "\n",
    "> Fine tuning, Textual Inversion, **DreamBooth**, LoRA, ...\n",
    "What are we fine-tuning?\n",
    "\n",
    "모델의 모든 파라미터를 Fine-tuning 에 참여시키는 것은 이미지의 특성이 수정되는 효과에 비해 과도한 연산량을 소모합니다.\n",
    "때문에 여러 경로를 통해 모델의 일부분만 가지고 우리가 주입하고 싶은 데이터를 스며들도록 하는 것이 포인트입니다.\n",
    "\n",
    "Huggingface - diffusers API 를 활용해 미세조정 작업을 수행해볼까요?\n",
    "> 1. 먼저 Huggingface 에 로그인\n",
    "2. 우측 상단의 Settings로 이동\n",
    "3. Access Token 페이지에서 New Token을 Read로 발급\n",
    "4. API key 를 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2fee7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.huggingface\n",
    "HUGGINGFACE_TOKEN = ['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']\n",
    "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "723ae677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path './diffusers_git' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers ./diffusers_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77c17c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD is now at df60b35e4 Release: v0.22.0\r\n"
     ]
    }
   ],
   "source": [
    "!cd diffusers_git && git checkout tags/v0.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6cf1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///aiffel/aiffel/diffusers_git\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (4.8.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (3.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (2021.11.10)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (1.21.4)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (8.3.2)\n",
      "Collecting huggingface-hub>=0.13.2\n",
      "  Using cached huggingface_hub-0.24.0-py3-none-any.whl (419 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (4.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (21.3)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (4.62.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata->diffusers==0.22.0) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (1.26.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.13.2->diffusers==0.22.0) (3.0.6)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building editable for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.22.0-0.editable-py3-none-any.whl size=10557 sha256=a495e2d2f1d9c95d22add67d39086fb31aad598744c29418ec88cf30c0583f61\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7ipi6b1w/wheels/c4/59/51/cb9b4bdaa28c529eccb1dcc812e9b2c7fa6e0c3bb2bee4b289\n",
      "Successfully built diffusers\n",
      "\u001b[33mWARNING: Error parsing requirements for huggingface-hub: [Errno 2] No such file or directory: '/opt/conda/lib/python3.9/site-packages/huggingface_hub-0.0.19.dist-info/METADATA'\u001b[0m\n",
      "\u001b[33mWARNING: Error parsing requirements for fsspec: [Errno 2] No such file or directory: '/opt/conda/lib/python3.9/site-packages/fsspec-2021.11.1.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: fsspec, safetensors, huggingface-hub, diffusers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.11.1\n",
      "    Can't uninstall 'fsspec'. No files were found to uninstall.\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.19\n",
      "    Can't uninstall 'huggingface-hub'. No files were found to uninstall.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 1.14.0 requires huggingface-hub<0.1.0,>=0.0.19, but you have huggingface-hub 0.24.0 which is incompatible.\u001b[0m\n",
      "Successfully installed diffusers-0.22.0 fsspec-2024.6.1 huggingface-hub-0.24.0 safetensors-0.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ./diffusers_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddf85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusers                     0.22.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55519b58",
   "metadata": {},
   "source": [
    "오늘은 실습을 위해 12 GB GPU에서도 구동할 수 있는 가벼운 모델을 불러와 학습시켜보겠습니다.\n",
    "\n",
    "먼저 몇가지 의존성 모듈을 설치해줘야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10f7394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate>=0.16.0\n",
      "  Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from -r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 2)) (0.10.1+cu111)\n",
      "Collecting transformers>=4.25.1\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.9/site-packages (from -r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: Jinja2 in /opt/conda/lib/python3.9/site-packages (from -r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 6)) (3.0.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (0.24.0)\n",
      "Collecting torch>=1.10.0\n",
      "  Using cached torch-2.3.1-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (1.21.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (5.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 2)) (8.3.2)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.1-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (3.4.0)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "     |████████████████████████████████| 731.7 MB 3.6 kB/s              ███████████████          | 502.8 MB 577 kB/s eta 0:06:37  \n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "     |████████████████████████████████| 410.6 MB 2.1 kB/s              \n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "     |████████████████████████████████| 121.6 MB 14 kB/s              \n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "     |████████████████████████████████| 99 kB 9.4 MB/s             \n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (2024.6.1)\n",
      "Collecting nvidia-nccl-cu12==2.20.5\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting triton==2.3.1\n",
      "  Using cached triton-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (2.6.3)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Using cached nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (2021.11.10)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (4.62.3)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (1.42.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (3.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (59.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (3.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (0.37.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from Jinja2->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (4.2.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (4.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->accelerate>=0.16.0->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 1)) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.25.1->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 3)) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r /aiffel/diffusers_git/examples/dreambooth/requirements.txt (line 5)) (3.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     |████████████████████████████████| 536 kB 94.4 MB/s            \n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, typing-extensions, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, wcwidth, torch, tokenizers, pillow, transformers, torchvision, ftfy, accelerate\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1+cu111\n",
      "    Uninstalling torch-1.9.1+cu111:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'layers_test.py'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting bitsandbytes==0.41.1\n",
      "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "     |████████████████████████████████| 92.6 MB 50 kB/s              \n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Successfully installed bitsandbytes-0.41.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting xformers==0.0.20\n",
      "  Downloading xformers-0.0.20-cp39-cp39-manylinux2014_x86_64.whl (109.1 MB)\n",
      "     |████████████████████████████████| 109.1 MB 6.1 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from xformers==0.0.20) (1.21.4)\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "     |████████████████████████████████| 619.9 MB 3.7 kB/s              \n",
      "\u001b[?25hCollecting pyre-extensions==0.0.29\n",
      "  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from pyre-extensions==0.0.29->xformers==0.0.20) (4.12.2)\n",
      "Collecting typing-inspect\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "     |████████████████████████████████| 54.6 MB 50 kB/s              \n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "     |████████████████████████████████| 63.3 MB 40 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch==2.0.1->xformers==0.0.20) (3.4.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch==2.0.1->xformers==0.0.20) (2.6.3)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "     |████████████████████████████████| 173.2 MB 8.6 kB/s             | 67.4 MB 42.8 MB/s eta 0:00:03��███████████████████▍  | 159.3 MB 68.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch==2.0.1->xformers==0.0.20) (1.13.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "     |████████████████████████████████| 21.0 MB 39 kB/s              \n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "     |████████████████████████████████| 11.8 MB 38 kB/s              \n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "     |████████████████████████████████| 98 kB 40 kB/s              \n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "     |████████████████████████████████| 849 kB 84.4 MB/s            \n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "     |████████████████████████████████| 102.6 MB 748 bytes/s          \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch==2.0.1->xformers==0.0.20) (3.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "     |████████████████████████████████| 317.1 MB 10 kB/s               \n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "     |████████████████████████████████| 177.1 MB 18 kB/s               \n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "     |████████████████████████████████| 557.1 MB 3.0 kB/s              ��████████     | 470.1 MB 278 kB/s eta 0:05:13  \n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "     |████████████████████████████████| 168.4 MB 16 kB/s                      | 80.8 MB 52.7 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->xformers==0.0.20) (59.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->xformers==0.0.20) (0.37.0)\n",
      "Collecting lit\n",
      "  Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "     |████████████████████████████████| 96 kB 69 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: cmake in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.20) (3.21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch==2.0.1->xformers==0.0.20) (2.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy->torch==2.0.1->xformers==0.0.20) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.20) (0.4.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: nvidia-cublas-cu11, lit, typing-inspect, triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, torch, pyre-extensions, xformers\n",
      "  Attempting uninstall: triton\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: triton 2.3.1\n",
      "    Uninstalling triton-2.3.1:\n",
      "      Successfully uninstalled triton-2.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.1+cu111 requires torch==1.9.1, but you have torch 2.0.1 which is incompatible.\n",
      "torchaudio 0.9.1 requires torch==1.9.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pyre-extensions-0.0.29 torch-2.3.1 triton-2.0.0 typing-inspect-0.9.0 xformers-0.0.20\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting accelerate==0.24.1\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "     |████████████████████████████████| 261 kB 41 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate==0.24.1) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.24.1) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.24.1) (1.21.4)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.9/site-packages (from accelerate==0.24.1) (0.24.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from accelerate==0.24.1) (2.3.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from accelerate==0.24.1) (5.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->accelerate==0.24.1) (3.0.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (2.20.5)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (2024.6.1)\n",
      "Collecting triton==2.3.1\n",
      "  Using cached triton-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.24.1) (2.6.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.24.1) (12.5.82)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->accelerate==0.24.1) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->accelerate==0.24.1) (4.62.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate==0.24.1) (2.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.24.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.24.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.24.1) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.24.1) (2.0.8)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate==0.24.1) (1.3.0)\n",
      "Installing collected packages: triton, accelerate\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.32.1\n",
      "    Uninstalling accelerate-0.32.1:\n",
      "      Successfully uninstalled accelerate-0.32.1\n",
      "Successfully installed accelerate-0.24.1 triton-2.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0) (3.4.0)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0) (18.1.8)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0) (2.3.1)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0) (3.21.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (2.6.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (12.1.105)\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "     |████████████████████████████████| 779.1 MB 6.7 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (4.12.2)\n",
      "  Downloading torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "     |████████████████████████████████| 755.5 MB 5.5 kB/s                               | 110.3 MB 146.8 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "     |████████████████████████████████| 166.0 MB 12 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (12.1.3.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "     |████████████████████████████████| 755.5 MB 3.7 kB/s              ��██▍    | 647.0 MB 49.2 MB/s eta 0:00:03 \n",
      "\u001b[?25h  Downloading torch-2.2.0-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "     |████████████████████████████████| 755.5 MB 636 bytes/s           \n",
      "\u001b[?25h  Downloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "     |████████████████████████████████| 670.2 MB 568 bytes/s          \n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "     |████████████████████████████████| 209.8 MB 161 bytes/s          \n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.1.1-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████▏           | 422.0 MB 4.0 MB/s eta 0:01:02    |██                              | 40.5 MB 53.4 MB/s eta 0:00:12                   | 119.6 MB 113 kB/s eta 1:20:46 ��████▉                          | 122.9 MB 113 kB/s eta 1:20:17         | 143.1 MB 113 kB/s eta 1:17:19 997.7 MB/s eta 0:00:09               | 180.3 MB 57.7 MB/s eta 0:00:09               | 185.4 MB 57.7 MB/s eta 0:00:097 B/s eta 0:05:24 1               | 212.0 MB 1.4 MB/s eta 0:05:19              | 212.5 MB 1.4 MB/s eta 0:05:19             | 215.5 MB 1.4 MB/s eta 0:05:17    |██████████▎                     | 215.7 MB 1.4 MB/s eta 0:05:16            | 215.9 MB 1.4 MB/s eta 0:05:16               | 219.5 MB 369 kB/s eta 0:20:21               | 223.1 MB 369 kB/s eta 0:20:11    |██████████▊                     | 224.2 MB 369 kB/s eta 0:20:08               | 228.0 MB 369 kB/s eta 0:19:58               | 230.4 MB 369 kB/s eta 0:19:51 ��█▏                    | 234.3 MB 369 kB/s eta 0:19:41  |███████████▎                    | 235.7 MB 369 kB/s eta 0:19:37  |███████████▊                    | 245.2 MB 61.1 MB/s eta 0:00:07 |███████████▉                    | 248.0 MB 61.1 MB/s eta 0:00:07�████████▉                    | 248.4 MB 61.1 MB/s eta 0:00:07             | 252.4 MB 61.1 MB/s eta 0:00:07     | 259.2 MB 61.1 MB/s eta 0:00:07          | 268.3 MB 61.1 MB/s eta 0:00:07     | 269.0 MB 1.4 MB/s eta 0:04:51      | 271.5 MB 1.4 MB/s eta 0:04:49 ��████                   | 272.8 MB 1.4 MB/s eta 0:04:48 4:48 s eta 0:04:47 ��████████▌                  | 283.3 MB 1.4 MB/s eta 0:04:41 ��████████▋                  | 285.7 MB 1.4 MB/s eta 0:04:39       | 289.5 MB 1.4 MB/s eta 0:04:36  MB/s eta 0:04:36 ███▊                | 328.8 MB 1.6 MB/s eta 0:03:31  MB 1.6 MB/s eta 0:03:29 �███████████████                | 335.3 MB 1.6 MB/s eta 0:03:27 █                | 335.5 MB 1.6 MB/s eta 0:03:27 ████                | 336.6 MB 702 kB/s eta 0:07:56 kB/s eta 0:07:55  |████████████████▏               | 338.6 MB 702 kB/s eta 0:07:53  |████████████████▌               | 344.6 MB 702 kB/s eta 0:07:44 �█████████████▋               | 346.8 MB 702 kB/s eta 0:07:41  |████████████████▋               | 348.6 MB 702 kB/s eta 0:07:38 ��██████▉               | 352.0 MB 702 kB/s eta 0:07:34  |████████████████▉               | 353.1 MB 702 kB/s eta 0:07:32 ��██               | 354.8 MB 702 kB/s eta 0:07:30 █               | 355.0 MB 702 kB/s eta 0:07:29  | 363.1 MB 1.1 MB/s eta 0:04:34 ███▌              | 366.1 MB 1.1 MB/s eta 0:04:32 ��███████▏             | 380.0 MB 1.1 MB/s eta 0:04:19 B 1.1 MB/s eta 0:04:18 ��███████▌             | 388.3 MB 65.6 MB/s eta 0:00:05��███████▋             | 390.5 MB 65.6 MB/s eta 0:00:05    |███████████████████▍            | 405.0 MB 65.6 MB/s eta 0:00:05    |███████████████████▊            | 413.2 MB 4.0 MB/s eta 0:01:04 ��████████████████▉            | 416.1 MB 4.0 MB/s eta 0:01:04     |████████████████████            | 419.0 MB 4.0 MB/s eta 0:01:03      |████████████████████████████████| 670.2 MB 790 bytes/s            | 423.0 MB 1.2 MB/s eta 0:03:21 ███████████████▎           | 423.9 MB 1.2 MB/s eta 0:03:21 ��███▍           | 427.9 MB 1.2 MB/s eta 0:03:18  �████████▏          | 442.9 MB 1.2 MB/s eta 0:03:05 444.0 MB 1.2 MB/s eta 0:03:04 ��█▍          | 447.2 MB 1.2 MB/s eta 0:03:02 �████████▌          | 450.6 MB 1.2 MB/s eta 0:03:00 �████████▋          | 452.8 MB 1.2 MB/s eta 0:02:59  MB 1.2 MB/s eta 0:02:59 ��████████████████▋          | 453.1 MB 1.2 MB/s eta 0:02:58 �██▎         | 466.4 MB 1.2 MB/s eta 0:02:48 ��████████████████████▎         | 467.5 MB 1.3 MB/s eta 0:02:36 ��████████████████████▍         | 469.5 MB 1.3 MB/s eta 0:02:35 �██▌         | 470.4 MB 1.3 MB/s eta 0:02:34 ��████████████████████▌         | 471.6 MB 1.3 MB/s eta 0:02:33         | 472.7 MB 1.3 MB/s eta 0:02:32 ��████████████████████▋         | 473.4 MB 1.3 MB/s eta 0:02:32 █████████████████▋         | 473.6 MB 1.3 MB/s eta 0:02:32 ��████████████████████▊         | 475.4 MB 1.3 MB/s eta 0:02:30 ��█████████████████████         | 479.4 MB 1.3 MB/s eta 0:02:27 B 227 kB/s eta 0:13:22 █▊        | 498.0 MB 227 kB/s eta 0:12:36 ��████████▉        | 498.2 MB 227 kB/s eta 0:12:35 B 227 kB/s eta 0:12:26 █████▏       | 506.3 MB 227 kB/s eta 0:11:59 █████▎       | 508.5 MB 1.3 MB/s eta 0:02:08 █████▌       | 512.5 MB 1.3 MB/s eta 0:02:05 █████████████████▊       | 517.5 MB 1.3 MB/s eta 0:02:01 ��██▊       | 518.8 MB 1.3 MB/s eta 0:02:00  1.3 MB/s eta 0:01:59 �████████████▉       | 520.3 MB 1.3 MB/s eta 0:01:58 ██████████████████       | 525.2 MB 1.3 MB/s eta 0:01:55  |█████████████████████████▏      | 526.8 MB 1.3 MB/s eta 0:01:53  |█████████████████████████▌      | 534.3 MB 69.7 MB/s eta 0:00:02��██▋      | 537.3 MB 69.7 MB/s eta 0:00:02 |█████████████████████████▉      | 541.8 MB 69.7 MB/s eta 0:00:02��█████████████████      | 543.1 MB 71.7 MB/s eta 0:00:02███████      | 543.2 MB 71.7 MB/s eta 0:00:02�██████████████      | 544.4 MB 71.7 MB/s eta 0:00:02��███      | 544.6 MB 71.7 MB/s eta 0:00:02.2 MB 71.7 MB/s eta 0:00:02��█████████████████      | 546.5 MB 71.7 MB/s eta 0:00:02 0:00:22  \n",
      "\u001b[?25h  Downloading torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "     |████████████████████████████████| 670.2 MB 489 bytes/s                                     | 3.2 MB 42.9 MB/s eta 0:00:16                             | 6.7 MB 42.9 MB/s eta 0:00:16 eta 0:00:16MB/s eta 0:00:16MB/s eta 0:00:16MB/s eta 0:00:16 | 21.2 MB 42.9 MB/s eta 0:00:16    |█▏                              | 24.2 MB 42.9 MB/s eta 0:00:16    |█▍                              | 29.9 MB 1.6 MB/s eta 0:06:50   |█▍                              | 30.2 MB 1.6 MB/s eta 0:06:50     |█▋                              | 32.8 MB 1.6 MB/s eta 0:06:48 ��█                              | 42.1 MB 1.6 MB/s eta 0:06:27 4.4 MB 1.6 MB/s eta 0:06:26                      | 61.2 MB 1.6 MB/s eta 0:06:15 1.5 MB 1.6 MB/s eta 0:06:15                      | 64.2 MB 1.6 MB/s eta 0:06:14 4.4 MB 1.6 MB/s eta 0:06:13 :13 ▎                            | 68.0 MB 1.6 MB/s eta 0:06:11          | 72.0 MB 1.6 MB/s eta 0:06:12                          | 73.6 MB 1.6 MB/s eta 0:06:11 ▌                            | 74.4 MB 1.6 MB/s eta 0:06:11  MB 61.9 MB/s eta 0:00:10 MB 61.9 MB/s eta 0:00:10��████▏                          | 107.4 MB 61.9 MB/s eta 0:00:10��████▍                          | 112.6 MB 238 kB/s eta 0:38:58    | 117.0 MB 238 kB/s eta 0:38:40 ��████▊                          | 118.8 MB 238 kB/s eta 0:38:32 ██▊                          | 119.0 MB 238 kB/s eta 0:38:31 �                          | 122.0 MB 238 kB/s eta 0:38:18 ��█████                          | 126.9 MB 238 kB/s eta 0:37:58         | 129.9 MB 238 kB/s eta 0:37:45         | 132.8 MB 238 kB/s eta 0:37:33         | 135.8 MB 1.3 MB/s eta 0:06:38         | 138.8 MB 1.3 MB/s eta 0:06:36  |██████▋                         | 139.0 MB 1.3 MB/s eta 0:06:35 █                         | 146.3 MB 1.3 MB/s eta 0:06:30  :06:27 0:06:26 25    :06:44  1                | 171.0 MB 1.3 MB/s eta 0:06:39                | 180.1 MB 112 kB/s eta 1:12:36                | 182.5 MB 112 kB/s eta 1:12:14                | 185.1 MB 112 kB/s eta 1:11:51                | 187.8 MB 112 kB/s eta 1:11:28                | 190.3 MB 112 kB/s eta 1:11:05 1 10:14 7 1 8 4             | 212.0 MB 1.3 MB/s eta 0:05:53              | 217.1 MB 61.6 MB/s eta 0:00:08    |██████████▍                     | 217.3 MB 61.6 MB/s eta 0:00:08              | 223.9 MB 61.6 MB/s eta 0:00:08              | 226.5 MB 61.6 MB/s eta 0:00:08            | 229.9 MB 61.6 MB/s eta 0:00:08   |███████████                     | 230.2 MB 61.6 MB/s eta 0:00:08              | 231.4 MB 61.6 MB/s eta 0:00:08             | 235.8 MB 61.6 MB/s eta 0:00:08▌                    | 241.9 MB 5.1 MB/s eta 0:01:24                   | 242.2 MB 5.1 MB/s eta 0:01:24 �███▉                    | 249.0 MB 5.1 MB/s eta 0:01:23  |████████████                    | 252.7 MB 5.1 MB/s eta 0:01:22      | 255.0 MB 5.1 MB/s eta 0:01:22      | 257.7 MB 1.8 MB/s eta 0:03:52 ��██████▍                   | 260.4 MB 1.8 MB/s eta 0:03:50 s eta 0:03:50      | 265.1 MB 1.8 MB/s eta 0:03:47      | 267.6 MB 1.8 MB/s eta 0:03:46 �███████████▉                   | 268.5 MB 1.8 MB/s eta 0:03:45      | 272.3 MB 1.8 MB/s eta 0:03:43           | 274.0 MB 1.8 MB/s eta 0:03:42 8 MB/s eta 0:03:42 �████▏                  | 274.6 MB 1.8 MB/s eta 0:03:42 ████▏                  | 275.7 MB 1.8 MB/s eta 0:03:41 ��████████▎                  | 277.3 MB 723 kB/s eta 0:09:03 ██▎                  | 277.5 MB 723 kB/s eta 0:09:03        | 277.7 MB 723 kB/s eta 0:09:03     |█████████████▎                  | 279.1 MB 723 kB/s eta 0:09:01 ��████████▊                  | 288.3 MB 723 kB/s eta 0:08:48        | 288.7 MB 723 kB/s eta 0:08:47       | 292.1 MB 723 kB/s eta 0:08:43 ��█████████                  | 293.2 MB 723 kB/s eta 0:08:41 �██▎                 | 299.1 MB 4.9 MB/s eta 0:01:16 .9 MB/s eta 0:01:15 .9 MB/s eta 0:01:14        | 305.9 MB 4.9 MB/s eta 0:01:14 .9 MB/s eta 0:01:14 .9 MB/s eta 0:01:13        | 315.5 MB 4.9 MB/s eta 0:01:12 �███                 | 315.7 MB 4.9 MB/s eta 0:01:12     |███████████████                 | 316.1 MB 4.9 MB/s eta 0:01:12 ███▏                | 318.2 MB 4.9 MB/s eta 0:01:12 ��█████▎                | 319.6 MB 4.9 MB/s eta 0:01:11  MB 4.9 MB/s eta 0:01:11 �███████████▎                | 320.0 MB 623 kB/s eta 0:09:22 ███▊                | 328.3 MB 623 kB/s eta 0:09:09 ███▊                | 330.2 MB 623 kB/s eta 0:09:06 kB/s eta 0:09:05 ��████████▉                | 330.6 MB 623 kB/s eta 0:09:05   | 330.8 MB 623 kB/s eta 0:09:05 �██████████████▉                | 331.0 MB 623 kB/s eta 0:09:04 ███▍              | 364.4 MB 133 kB/s eta 0:38:08 ███▊              | 370.4 MB 450 kB/s eta 0:11:05 ta 0:00:03 MB 80.8 MB/s eta 0:00:03��████████████████████▏         | 464.6 MB 89.9 MB/s eta 0:00:030:00:03��████████████████████▌         | 470.8 MB 89.9 MB/s eta 0:00:039 MB/s eta 0:00:03��██████████████████████▉        | 498.3 MB 2.6 MB/s eta 0:01:06 █████████████████▎       | 507.6 MB 2.6 MB/s eta 0:01:02 █████▋       | 514.3 MB 2.6 MB/s eta 0:01:00 █████▋       | 516.1 MB 2.6 MB/s eta 0:00:59 █████▊       | 518.1 MB 2.6 MB/s eta 0:00:58 █████▉       | 520.1 MB 1.2 MB/s eta 0:02:11 ��███       | 522.6 MB 1.2 MB/s eta 0:02:08 ��████████████████▎      | 528.3 MB 1.2 MB/s eta 0:02:03 ��████████████████▊      | 538.4 MB 1.2 MB/s eta 0:01:55 .8 MB 1.2 MB/s eta 0:01:49 ��█████████████████      | 546.6 MB 77.7 MB/s eta 0:00:02  | 571.6 MB 77.7 MB/s eta 0:00:02��██▌    | 575.5 MB 133.1 MB/s eta 0:00:01████████▉    | 582.7 MB 133.1 MB/s eta 0:00:01ta 0:00:01�▋   | 598.4 MB 91.9 MB/s eta 0:00:01 a 0:00:01 ��████▏  | 611.1 MB 91.9 MB/s eta 0:00:01 ��████████████████████████▎  | 613.9 MB 93 kB/s eta 0:09:59   ta 0:00:0145.1 MB 116.3 MB/s eta 0:00:01��████████ | 650.3 MB 116.3 MB/s eta 0:00:01��██████████████▋| 661.0 MB 116.3 MB/s eta 0:00:01████▊| 663.5 MB 116.3 MB/s eta 0:00:01 0:00:01█████| 668.1 MB 112.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Using cached torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.10.3.66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (11.7.4.91)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch->triton==2.0.0) (1.13.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->triton==2.0.0) (59.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->triton==2.0.0) (0.37.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch->triton==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy->torch->triton==2.0.0) (1.3.0)\n",
      "Installing collected packages: torch, triton\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.3.1\n",
      "    Uninstalling triton-2.3.1:\n",
      "      Successfully uninstalled triton-2.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.18.1 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.\n",
      "torchaudio 0.9.1 requires torch==1.9.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-2.0.1 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ~/diffusers_git/examples/dreambooth/requirements.txt\n",
    "!pip uninstall -y bitsandbytes\n",
    "!pip install bitsandbytes==0.41.1\n",
    "!pip install xformers==0.0.20\n",
    "!pip install accelerate==0.24.1\n",
    "!pip install triton==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fde38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /aiffel/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate config default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5846f0f",
   "metadata": {},
   "source": [
    "Dreambooth 방식으로 미세조정을 수행하기 위해서는 몇 가지 종류의 데이터를 준비해야합니다.\n",
    "\n",
    "* Unique class: 학습 시키려는 예시를 포괄하는 dog, person 등의 중간 카테고리로 클래스를 설정해줍니다. 우리는 dog 를 사용하도록 하겠습니다.\n",
    "\n",
    "* Unique identifier: 학습 시키고싶은 특정한 대상을 위해, 이전 어휘와 겹치지않는 유일한 단어를 identifier, ID 로 설정해줍니다. 이때 아무 의미를 지니지 않은 무작위의 단어 조합을 선택하도록합니다. 이 예시에서는 **sks** 와 같이 최대한 아무 의미를 가지지 않는 단어를 사용했습니다.\n",
    "\n",
    "* Class prompt: 특정한 ID 를 제외하고 이미지에 대한 설명을 넣어주도록 합니다. \"a photo of dog\".\n",
    "\n",
    "* Instance prompt: 학습시킬 대상 이미지들이 표기되어있는 설명 문장을 입력합니다. 예시로 다음과 같은 형식을 사용할 수 있습니다 - f\"a photo of {unique_id} {unique_class}\". 예제에서 사용할 ID 와 클래스를 조합하면 \"a photo of sks dog\" 와 같은 문장을 만들 수 있습니다.\n",
    "\n",
    "* Class images: class prompt 에 맞추어 학습시킬 대상을 포함하는 넓은 범위의 이미지를 모읍니다. 일반적으로 200-300 장 정도면 충분합니다.\n",
    "\n",
    "* Instance images: instance prompt 와 연결하여 학습할 수 있는 이미지를 모읍니다. 학습시키고싶은 동일한 대상으로 3 - 5 장 만 마련하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b0aff",
   "metadata": {},
   "source": [
    "예제 튜토리얼을 따라 사용할 이미지 데이터를 불러오겠습니다.\n",
    "dreambooth 를 위해서는 5 장 정도의 instance 이미지만 있으면 충분합니다! 놀랍지않나요?\n",
    "나중에 SD 모델에 적용하고싶은 대상있다면, 대상의 모습이 담긴 이미지를 모아 아래처럼 경로를 만들어 저장해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ce035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40c82526aa64434afc7078529fdeb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af6fa000e5f4ed6a9911372bd96c836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "alvan-nee-brFsZ7qszSY-unsplash.jpeg:   0%|          | 0.00/1.19M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673a058e39e747908b60ea9a59cee48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "alvan-nee-Id1DBHv4fbg-unsplash.jpeg:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee367d92a6741ea8765ba5da5b651b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "alvan-nee-eoqnr8ikwFE-unsplash.jpeg:   0%|          | 0.00/1.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347677ec7e1c4059bc33f206a539d7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "alvan-nee-bQaAJCbNq3g-unsplash.jpeg:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300fab428aaf4b4187273590bc405423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "alvan-nee-9M0tSjb-cpA-unsplash.jpeg:   0%|          | 0.00/677k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/diffusers_git/examples/dreambooth/dog'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = \"./diffusers_git/examples/dreambooth/dog\"\n",
    "snapshot_download(\n",
    "    \"diffusers/dog-example\",\n",
    "    local_dir=local_dir, repo_type=\"dataset\",\n",
    "    ignore_patterns=\".gitattributes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba90d3",
   "metadata": {},
   "source": [
    "SD 모델의 학습 코드에는 여러 종류의 인자들이 입력되어야합니다.\n",
    "각 조건들을 좀더 편리하게 입력하기 위해 아래와 같이 셸 스크립트 shell script를 구성해주어야합니다. CLI 터미널에서 sh 명령어로 해당 스크립트를 실행할 수 있습니다.\n",
    "\n",
    "Ipython 의 다양한 매직 커맨드 %, %%를 활용하면 유용한 작업을 쉽게 실행할 수 있습니다\n",
    "%%writefile {file_path} 커맨드는 셀 안의 내용을 텍스트 파일로 저장해줍니다\n",
    "\n",
    "셸 스크립트 내의 외부환경변수 MODEL_NAME 은 Huggingface 에 등록된 여러 사전학습 모델들을 이름으로 쉽게 불러올 수 있습니다.\n",
    "INSTANCE_DIR 에는 학습시키고 싶은 특정 대상의 이미지를 5-6 장 정도 넣어줍니다.\n",
    "CLASS_DIR은 학습시키고 싶은 대상과 닮은 참고 이미지들을 넣어줍니다. 여유가 된다면 200 - 300 장 정도 채워줄 수 있습니다. 빠른 진행을 위해 over-fitting 을 감수하고 이번에는 인스턴스와 동일하게 입력하도록 합니다.\n",
    "OUTPUT_DIR 경로에는 학습을 통해 만들어진 파라미터, 출력 결과 등이 저장됩니다.\n",
    "\n",
    "다만, 이번 노드에서는 입력해야하는 텍스트가 많아 data 폴더 안에 셸 스크립트를 미리 준비해놓았습니다. 구성 내용은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6d1395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompVis/stable-diffusion-v1-4\n",
      "Traceback (most recent call last):\n",
      "  File \"/aiffel/diffusers_git/examples/dreambooth/train_dreambooth.py\", line 42, in <module>\n",
      "    from torchvision import transforms\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchvision/_meta_registrations.py\", line 4, in <module>\n",
      "    import torch._custom_ops\n",
      "ModuleNotFoundError: No module named 'torch._custom_ops'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 994, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 636, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python3.9', '/aiffel/diffusers_git/examples/dreambooth/train_dreambooth.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--instance_data_dir=./diffusers_git/examples/dreambooth/dog', '--class_data_dir=./diffusers_git/examples/dreambooth/dog', '--output_dir=./diffusers_git/examples/dreambooth/data', '--instance_prompt=a photo of sks dog', '--class_prompt=a photo of dog', '--train_batch_size=1', '--with_prior_preservation', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--use_8bit_adam', '--enable_xformers_memory_efficient_attention', '--set_grads_to_none', '--learning_rate=2e-6', '--lr_warmup_steps=0', '--num_class_images=5', '--max_train_steps=100']' returned non-zero exit status 1.\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "학습 완료!!\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "!sh ~/data/train_dreambooth.sh\n",
    "\n",
    "print('----'*64)\n",
    "print('학습 완료!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb562da",
   "metadata": {},
   "source": [
    "학습이 완료되었습니다! data 경로에 학습된 결과물이 저장되었는지 확인할 수 있겠네요.\n",
    "그럼 이제 모델의 출력물을 확인해봐야겠죠? 추론 과정을 위해 별도의 파이프라인을 만들고 학습된 파라미터들을 불러와 생성작업에 활용해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e748552",
   "metadata": {},
   "source": [
    "#### Inference with ckeckpoints\n",
    "SD 모델이 이미 묵직하게 메모리를 차지하고 있고, 의존성 문제도 해결해야하기 때문에 %reset 매직 커맨드로 커널을 한번 초기화해주겠습니다.\n",
    "추론 과정 중 주요 함수에서 버전 문제가 발생하기때문에 부득이 diffusers 모듈도 재설치 해줍니다.\n",
    "\n",
    "추론을 위한 새로운 파이프라인을 구성해주겠습니다.\n",
    "학습을 통해 저장된 체크포인트 가중치를 불러와 추론과정에 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a33758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: diffusers 0.22.0\n",
      "Uninstalling diffusers-0.22.0:\n",
      "  Successfully uninstalled diffusers-0.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting diffusers==0.22.0\n",
      "  Using cached diffusers-0.22.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (0.24.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (10.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (1.21.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (2.26.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.9/site-packages (from diffusers==0.22.0) (4.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (4.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (21.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers==0.22.0) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata->diffusers==0.22.0) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers==0.22.0) (2021.10.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.13.2->diffusers==0.22.0) (3.0.6)\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'UNet2DConditionModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2120130887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 앞서 학습 코드로 만들어진 파라미터들을 로드합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet2DConditionModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./diffusers_git/examples/dreambooth/data/unet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPTextModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./diffusers_git/examples/dreambooth/data/text_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UNet2DConditionModel' is not defined"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "# 의존성 모듈을 삭제 후 다시 설치합니다.\n",
    "\n",
    "!pip uninstall -y diffusers\n",
    "!pip install diffusers==0.22.0\n",
    "\n",
    "# from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
    "# from transformers import CLIPTextModel\n",
    "# import torch\n",
    "\n",
    "# huggingface에 미리 등록된 base 모델을 다운로드하여 사용합니다.\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "# 앞서 학습 코드로 만들어진 파라미터들을 로드합니다.\n",
    "unet = UNet2DConditionModel.from_pretrained(\"./diffusers_git/examples/dreambooth/data/unet\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"./diffusers_git/examples/dreambooth/data/text_encoder\")\n",
    "\n",
    "# stable diffusion 의 전체 파이프라인을 구성해줍니다.\n",
    "pipeline = DiffusionPipeline.from_pretrained(model_id, unet=unet, text_encoder=text_encoder, dtype=torch.float16)\n",
    "pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becfece",
   "metadata": {},
   "source": [
    "모델에 입력할 텍스트 프롬프트를 설정하고, INSTANCE, CLASS 정보도 꼼꼼하게 추가해줍니다.\n",
    "inference step, guidence_scale 인자를 조정하여 출력물의 퀄리티를 높여봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f886c93c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/4069935494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"A photo of sks dog chasing a car\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog-bucket.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = \"A photo of sks dog chasing a car\"\n",
    "image = pipeline(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "\n",
    "image.save(\"dog-bucket.png\")\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515d0e4",
   "metadata": {},
   "source": [
    "### Stable diffusion 실습(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2184bc",
   "metadata": {},
   "source": [
    "#### 나만의 취향, 한 숫갈 듬뿍\n",
    "무궁무진한 가능성을 담고 있는 stable diffusion 안에서 우리가 원하는 방향으로 이미지를 바꿀 수 있는 가능성을 엿보았습니다.\n",
    "더 뛰어난 수준의 이미지를 만들기 위해서는 어떤 것들이 필요한지 알아봅시다.\n",
    "\n",
    "Stable diffusion 과 함께 폭발적으로 성장하고 있는 사이트를 알고 계신가요?\n",
    "\n",
    "[CIVITai.com](https://www.civitai.com)\n",
    "\n",
    "SD 모델의 구현 코드들이 인터넷에 공개 된 이후, 여러 사람들이 모델을 이모양 저모양으로 뜯어보면서 아주 다양한 시도들을 수행해왔습니다.\n",
    "위 사이트는 저작권 문제 등 여러 논란의 중심이기도 하면서, 동시에 정말 많은 사람들의 호기심과 노력이 결집된 곳이기도 합니다.\n",
    "사이트 페이지를 둘러보다 보면 자주 마주치는 단어들이 있는 것 같습니다.\n",
    "\n",
    "* CHECKPOINT\n",
    "* LORA\n",
    "\n",
    "바로 이 두 가지 개념을 조합하여 우리도 마음껏 나만의 상상을 이미지로 만들어볼 수 있답니다.\n",
    "checkpoint는 간단하게 말해 미세조정을 거쳐 저장한 SD 모델의 파라미터(가중치) 입니다.\n",
    "우리도 앞 페이지에서 학습해봤듯이, 개인 작업자들이 각자 데이터를 마련하여 본인의 방향성에 맞춰 생성 모델의 가중치들을 업데이트하여 웹 상에 공개할 수 있습니다.\n",
    "사이트에 공유된 가중치를 그대로 다운로드받아 모델 파이프라인을 구성하여 탑재할 수 있습니다.\n",
    "\n",
    "다른 한 가지, 생소하기도한 LoRA 는 무엇일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ccbad",
   "metadata": {},
   "source": [
    "###### Lora\n",
    "Stable diffusion 이 아주 복잡하고 큰 시스템인 만큼, 데이터셋, text inversion, dreambooth 등 전체 모델의 일부분을 통해 미세 조정하는 방식은 아주 다양하게 개발되었습니다.\n",
    "하지만 여전히 SD 모델의 큰 덩치(파라미터)는 많은 연산량을 요구하기 떄문에, 디바이스 수준의 다양한 지점에서 활용하는데 자주 걸림돌로 작용합니다.\n",
    "\n",
    "이와 비슷한 문제를 동시에 겪고 있던 대규모 자연어 모델 Large Language Model, LLM 분야에서 한 가지 특별한 아이디어가 제안됩니다.\n",
    "바로 **Low Rank Adaptation 간단하게 LoRA** 라고 불리는 미세 조정 기법입니다.\n",
    "**기존의 over-parameter model 내부에서 본질적인 의미를 담고 있는 파라미터의 rank가 낮다(전체가 아닌 일부이다)고 주장하는 연구 결과에서 영감을 받은 LoRA는, 대규모 모델의 파라미터를 저차원 공간으로 투영하는 방식을 활용**합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9f2dc",
   "metadata": {},
   "source": [
    "![low Rank Adaption](./LoRA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087888eb",
   "metadata": {},
   "source": [
    "학습 시 pre-trained model의 initialized weight인 𝑊0는 동결시켜 가중치 업데이트를 하지 않고, 길이𝑟만큼의 low rank를 형성하는 행렬 𝐴와𝐵를 업데이트합니다.\n",
    "저차원 공간으로 투영된 파라미터는 특정 작업에 더 적합하도록 부분적으로 학습될 수 있습니다.\n",
    "전체 파라미터 중 일부분에만 추가적으로 높은 가중치를 두어, 활용하고자 하는 문제에 알맞는 부분만 따로 활성화 하는 방식이라고 이해할 수 있을 것 같습니다.\n",
    "LoRA는 대규모 언어 모델의 파라미터 수를 줄여서 학습 속도를 높이고, 과적합을 방지하는 역할을 한다고 알려져있습니다.\n",
    "\n",
    "Stable diffusion도 모델의 가중치를 전부 업데이트하는 일반적인 미세 조정 방식은 생각보다 훨씬 많은 컴퓨터 연산량을 필요로 하며 결과에 비해 효율적이지 못한 것으로 보입니다.\n",
    "때문에 SD 모델 내부의 일부분만을 강조하여 우리가 원하는 이미지 특성만 강조하여 활용하는 방식인 LoRA 가 대중화되었고,\n",
    "다양한 LoRA 가중치들을 선택하여 파이프라인에 넣고 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b704b99",
   "metadata": {},
   "source": [
    "##### Checkpoint 에 LoRA 덧칠하기\n",
    "이제 직접 CHECKPOINT 와 LORA 를 적용하여 다양한 이미지를 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08693cc",
   "metadata": {},
   "source": [
    "civitai.com의 웹페이지를 보시면 샘플 이미지를 재현하기 위한 몇 가지 조건을 확인할 수 있습니다.\n",
    "\n",
    "1. Checkpoint : 직접 다운로드하여 파이프라인에 로드할 수 있고, huggingface 에 이미 업로드 되어있다면 해당 모델 ID 를 넣어 사용할 수 있습니다.\n",
    "2. LoRA : 상대적으로 적은 용량의 파일이기 떄문에 다운로드하여 활용하겠습니다.\n",
    "3. promt + negative_prompt : 상세한 프롬프트를 복사해와서 내 상황에 맞게 조금씩 변경하여 입력해줍니다.\n",
    "4. 기타 조건\n",
    "\n",
    "먼저 2 의 다운로드 링크를 통해 LoRA 파일을 lora_example.safetensors 라는 파일 이름으로 저장해두겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aa940fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-23 04:52:31--  https://civitai.com/api/download/models/116417\n",
      "Resolving civitai.com (civitai.com)... 104.22.19.237, 104.22.18.237, 172.67.12.143, ...\n",
      "Connecting to civitai.com (civitai.com)|104.22.19.237|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/1559796/model/E58AA8E789A9E6A8A1E59E8BE4B8A8.r2Ur.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22%E5%8A%A8%E7%89%A9%E6%A8%A1%E5%9E%8B%E4%B8%A8%E6%9F%AF%E5%9F%BA%20MG_CORGI_V1.1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20240723/us-east-1/s3/aws4_request&X-Amz-Date=20240723T045231Z&X-Amz-SignedHeaders=host&X-Amz-Signature=679a48edceaf1c9ae37b2377ce581009c5a7b8ac94f8e1d2878b67a096c7989f [following]\n",
      "--2024-07-23 04:52:31--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/1559796/model/E58AA8E789A9E6A8A1E59E8BE4B8A8.r2Ur.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22%E5%8A%A8%E7%89%A9%E6%A8%A1%E5%9E%8B%E4%B8%A8%E6%9F%AF%E5%9F%BA%20MG_CORGI_V1.1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20240723/us-east-1/s3/aws4_request&X-Amz-Date=20240723T045231Z&X-Amz-SignedHeaders=host&X-Amz-Signature=679a48edceaf1c9ae37b2377ce581009c5a7b8ac94f8e1d2878b67a096c7989f\n",
      "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 104.18.8.90, 104.18.9.90, 2606:4700::6812:95a, ...\n",
      "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|104.18.8.90|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 151110936 (144M) [application/octet-stream]\n",
      "Saving to: ‘lora_example.safetensors’\n",
      "\n",
      "lora_example.safete 100%[===================>] 144.11M  96.4MB/s    in 1.5s    \n",
      "\n",
      "2024-07-23 04:52:33 (96.4 MB/s) - ‘lora_example.safetensors’ saved [151110936/151110936]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://civitai.com/api/download/models/116417 -O lora_example.safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d901884",
   "metadata": {},
   "source": [
    "필요한 Checkpoint 는 편리하게도 huggingface 에 미리 올려진 상태입니다. 빨간 박스 부분의 이름을 복사하여 아래 코드에 넣어주겠습니다.\n",
    "프롬프트와 네거티브 프롬프트도 조금 변경하여 입력하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569c04fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\nFailed to import transformers.models.clip.image_processing_clip because of the following error (look up to see its traceback):\nNo module named 'torch._custom_ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/clip/image_processing_clip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_size_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m from ...image_transforms import (\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_processing_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from .image_utils import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_custom_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._custom_ops'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIPImageProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPTextModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1570\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.clip.image_processing_clip because of the following error (look up to see its traceback):\nNo module named 'torch._custom_ops'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_285/3072779118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDPMSolverMultistepScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"digiplay/hellofantasytime_v1.22\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 알맞은 모델 ID 를 입력합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPMSolverMultistepScheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    713\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\nFailed to import transformers.models.clip.image_processing_clip because of the following error (look up to see its traceback):\nNo module named 'torch._custom_ops'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"digiplay/hellofantasytime_v1.22\", torch_dtype=torch.float16)   # 알맞은 모델 ID 를 입력합니다.\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n",
    "pipeline.to(\"cuda\")\n",
    "\n",
    "pipeline.load_lora_weights(\"./lora_example.safetensors\")   # 다운로드한 LoRA 를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d86cc99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet-pytorch          0.7.1\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef070c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
