{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6f5a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15b796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4ad034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86435f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eadf16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f973ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트(sentences)를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10631cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58b305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3762d3ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2911302848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. 문장길이가 같지 않다.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73619116",
   "metadata": {},
   "source": [
    "### 문장길이 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f179842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee503021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.01549572 -0.01690245  0.0187917   0.04434301]\n",
      "  [-0.03284534 -0.04162493  0.00039983  0.04613102]\n",
      "  [ 0.00722556  0.00261819 -0.02264717  0.00418426]\n",
      "  [ 0.00328543 -0.00699751 -0.01630334  0.01355224]\n",
      "  [-0.03400898 -0.02220172 -0.01585195  0.04078715]]\n",
      "\n",
      " [[-0.01549572 -0.01690245  0.0187917   0.04434301]\n",
      "  [-0.03284534 -0.04162493  0.00039983  0.04613102]\n",
      "  [-0.004714   -0.02056557  0.0402495   0.03434977]\n",
      "  [-0.02196722 -0.03503066  0.04154703  0.01033411]\n",
      "  [-0.03400898 -0.02220172 -0.01585195  0.04078715]]\n",
      "\n",
      " [[-0.01549572 -0.01690245  0.0187917   0.04434301]\n",
      "  [ 0.02948802  0.00803284 -0.0441577   0.01223893]\n",
      "  [-0.03284534 -0.04162493  0.00039983  0.04613102]\n",
      "  [ 0.00722556  0.00261819 -0.02264717  0.00418426]\n",
      "  [-0.03914399 -0.00553923  0.02609495  0.00617624]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0005d",
   "metadata": {},
   "source": [
    "### RNN 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bc7d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8566db",
   "metadata": {},
   "source": [
    "### 1D CNN 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb8e3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6d1896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling만 적용한 경우\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D()) # 이거 하나만 적용\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df6156",
   "metadata": {},
   "source": [
    "### 본격적인 감성분석\n",
    "imdb.load_data() 호출 시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면, 그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ed0752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "# 긍정은 1, 부정은 0\n",
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d1abb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b871e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b648f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d51d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d35f06c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ec339",
   "metadata": {},
   "source": [
    "### 문장길이 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fb7f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82677a9",
   "metadata": {},
   "source": [
    "유의해야 하는 것은 padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느 쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1875f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580) (25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570ab00",
   "metadata": {},
   "source": [
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 됩니다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적입니다. 따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5daa442",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8e53ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa2fbcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2401171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 9s 68ms/step - loss: 0.6931 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5007\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 50ms/step - loss: 0.6928 - accuracy: 0.5053 - val_loss: 0.6929 - val_accuracy: 0.5007\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6923 - accuracy: 0.5114 - val_loss: 0.6925 - val_accuracy: 0.5009\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.6893 - accuracy: 0.5113 - val_loss: 0.6910 - val_accuracy: 0.5048\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6843 - accuracy: 0.5187 - val_loss: 0.6912 - val_accuracy: 0.5087\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 52ms/step - loss: 0.6924 - accuracy: 0.5320 - val_loss: 0.6842 - val_accuracy: 0.5184\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.6763 - accuracy: 0.5383 - val_loss: 0.6827 - val_accuracy: 0.5203\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 50ms/step - loss: 0.6663 - accuracy: 0.5768 - val_loss: 0.6579 - val_accuracy: 0.7217\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6705 - accuracy: 0.5757 - val_loss: 0.6950 - val_accuracy: 0.4989\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 50ms/step - loss: 0.6918 - accuracy: 0.5158 - val_loss: 0.6937 - val_accuracy: 0.5003\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6900 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5036\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6846 - accuracy: 0.5315 - val_loss: 0.6795 - val_accuracy: 0.5285\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 50ms/step - loss: 0.6361 - accuracy: 0.6229 - val_loss: 0.6923 - val_accuracy: 0.5062\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6897 - accuracy: 0.5232 - val_loss: 0.6936 - val_accuracy: 0.5017\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.6894 - accuracy: 0.5234 - val_loss: 0.6927 - val_accuracy: 0.5023\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 49ms/step - loss: 0.6883 - accuracy: 0.5254 - val_loss: 0.6920 - val_accuracy: 0.5037\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.6872 - accuracy: 0.5273 - val_loss: 0.6915 - val_accuracy: 0.5038\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.6861 - accuracy: 0.5284 - val_loss: 0.6910 - val_accuracy: 0.5059\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.6849 - accuracy: 0.5290 - val_loss: 0.6905 - val_accuracy: 0.5064\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 50ms/step - loss: 0.6836 - accuracy: 0.5297 - val_loss: 0.6902 - val_accuracy: 0.5073\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9eedf003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 6ms/step - loss: 0.6905 - accuracy: 0.5103\n",
      "[0.6905028820037842, 0.5102800130844116]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37dad5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2db9e9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "253ab1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0DklEQVR4nO3debxVdb3/8deHA3g4gIwHB5BBAyl+yCiaI+YQKUGOSZSSXXHIvNrNtCj1UtxrZeXPsu7FcigpbLpEiZlaXv1lKWhoKqJoqKAcZQaR8Xx+f3zXgs1m73P2tPY++5z38/HYj73m9dnr7LM++/td6/td5u6IiIika1fpAEREpGVSghARkYyUIEREJCMlCBERyUgJQkREMlKCEBGRjJQgJGdmdr+ZXVjqZSvJzJab2SkJbNfN7H3R8H+Z2VdzWbaA/Uw1sz8WGqdIU0ztIFo3M9ucMloHbAN2ReOXuPuc8kfVcpjZcuBf3P2hEm/XgcHuvqxUy5rZQOCfQAd331mSQEWa0L7SAUiy3L1LPNzUydDM2uukIy2Fvo8tg6qY2igzG29mK8zsWjNbBdxpZj3M7Pdm9o6ZrYuG+6Ws84iZ/Us0PM3M/p+Z3Rwt+08z+0iByw4ys0fNbJOZPWRmt5nZPVniziXGr5nZX6Lt/dHMeqfM/5SZvWZma8xsRhPH5ygzW2VmNSnTzjSzZ6PhcWb2VzNbb2Zvmdn3zaxjlm3dZWZfTxm/JlrnTTO7KG3ZM8zs72a20czeMLMbU2Y/Gr2vN7PNZvbB+NimrH+MmS00sw3R+zG5Hps8j3NPM7sz+gzrzGxeyrzJZrY4+gyvmNmEaPpe1XlmdmP8dzazgVFV22fM7HXgT9H0X0Z/hw3Rd2RYyvqdzOzb0d9zQ/Qd62Rm95nZ59I+z7NmdmamzyrZKUG0bQcCPYEBwHTC9+HOaLw/8B7w/SbWPwpYCvQGvgn82MysgGV/BjwJ9AJuBD7VxD5zifETwKeBPkBH4AsAZvYB4IfR9g+O9tePDNz9CeBd4ENp2/1ZNLwLuDr6PB8ETgYubyJuohgmRPGcCgwG0q9/vAtcAHQHzgAuM7OPRfNOiN67u3sXd/9r2rZ7AvcBt0af7TvAfWbWK+0z7HNsMmjuOP+UUGU5LNrWd6MYxgE/Aa6JPsMJwPIs+8jkROD9wIej8fsJx6kP8DSQWiV6MzAGOIbwPf4i0AjcDXwyXsjMRgB9CcdG8uHuerWRF+Ef9ZRoeDywHahtYvmRwLqU8UcIVVQA04BlKfPqAAcOzGdZwslnJ1CXMv8e4J4cP1OmGL+SMn458Ido+Hpgbsq8ztExOCXLtr8O3BENdyWcvAdkWfYq4H9Sxh14XzR8F/D1aPgO4KaU5YakLpthu7cA342GB0bLtk+ZPw34f9Hwp4An09b/KzCtuWOTz3EGDiKciHtkWO6/43ib+v5F4zfGf+eUz3ZoEzF0j5bpRkhg7wEjMixXC6wjXNeBkEh+kMT/VGt/qQTRtr3j7lvjETOrM7P/jorsGwlVGt1Tq1nSrIoH3H1LNNglz2UPBtamTAN4I1vAOca4KmV4S0pMB6du293fBdZk2xehtHCWme0HnAU87e6vRXEMiapdVkVx/AehNNGcvWIAXkv7fEeZ2Z+jqp0NwKU5bjfe9mtp014j/HqOZTs2e2nmOB9C+Juty7DqIcArOcabye5jY2Y1ZnZTVE21kT0lkd7RqzbTvqLv9L3AJ82sHTCFUOKRPClBtG3pt7D9G3A4cJS778+eKo1s1Ual8BbQ08zqUqYd0sTyxcT4Vuq2o332yrawu79AOMF+hL2rlyBUVb1I+JW6P/DlQmIglKBS/QyYDxzi7t2A/0rZbnO3HL5JqBJK1R9YmUNc6Zo6zm8Q/mbdM6z3BnBYlm2+Syg9xg7MsEzqZ/wEMJlQDdeNUMqIY1gNbG1iX3cDUwlVf1s8rTpOcqMEIam6Eort66P67BuS3mH0i3wRcKOZdTSzDwIfTSjGXwETzey46ILyTJr/H/gZ8K+EE+Qv0+LYCGw2s6HAZTnG8Atgmpl9IEpQ6fF3Jfw63xrV538iZd47hKqdQ7NsewEwxMw+YWbtzezjwAeA3+cYW3ocGY+zu79FuDbwg+hidgczixPIj4FPm9nJZtbOzPpGxwdgMXB+tPxY4JwcYthGKOXVEUppcQyNhOq675jZwVFp44NRaY8oITQC30alh4IpQUiqW4BOhF9nfwP+UKb9TiVc6F1DqPe/l3BiyOQWCozR3Z8HPks46b9FqKde0cxqPydcOP2Tu69Omf4Fwsl7E3B7FHMuMdwffYY/Acui91SXAzPNbBPhmskvUtbdAswC/mLh7qmj07a9BphI+PW/hnDRdmJa3Lm6haaP86eAHYRS1NuEazC4+5OEi+DfBTYA/8ueUs1XCb/41wH/zt4lskx+QijBrQReiOJI9QXgH8BCYC3wDfY+p/0EGE64piUFUEM5aXHM7F7gRXdPvAQjrZeZXQBMd/fjKh1LtVIJQirOzI40s8OiKokJhHrneRUOS6pYVH13OTC70rFUMyUIaQkOJNyCuZlwD/9l7v73ikYkVcvMPky4XtNA89VY0gRVMYmISEYqQYiISEatprO+3r17+8CBAysdhohIVXnqqadWu3t9pnmtJkEMHDiQRYsWVToMEZGqYmbpre93UxWTiIhkpAQhIiIZKUGIiEhGreYahIhUzo4dO1ixYgVbt25tfmGpiNraWvr160eHDh1yXkcJQkSKtmLFCrp27crAgQPJ/swoqRR3Z82aNaxYsYJBgwblvJ6qmESkaFu3bqVXr15KDi2UmdGrV6+8S3hKECJSEkoOLVshfx8lCKl6CxbA8uWVjkKk9VGCkKrmDmefDd/5TqUjkUpas2YNI0eOZOTIkRx44IH07dt39/j27dubXHfRokVceeWVze7jmGOOKVW4VUMXqaWqrVsHW7dCQ0OlI5F8zJkDM2bA669D//4waxZMnVr49nr16sXixYsBuPHGG+nSpQtf+MIXds/fuXMn7dtnPt2NHTuWsWPHNruPxx9/vPAAq5RKEFLV4sTwzjuVjUNyN2cOTJ8Or70WSoCvvRbG58wp7X6mTZvGpZdeylFHHcUXv/hFnnzyST74wQ8yatQojjnmGJYuXQrAI488wsSJE4GQXC666CLGjx/PoYceyq233rp7e126dNm9/Pjx4znnnHMYOnQoU6dOJe4Ve8GCBQwdOpQxY8Zw5ZVX7t5uquXLl3P88cczevRoRo8evVfi+cY3vsHw4cMZMWIE1113HQDLli3jlFNOYcSIEYwePZpXXnmltAeqCSpBSFVTgqg+M2bAli17T9uyJUwvphSRyYoVK3j88cepqalh48aNPPbYY7Rv356HHnqIL3/5y/z617/eZ50XX3yRP//5z2zatInDDz+cyy67bJ+2A3//+995/vnnOfjggzn22GP5y1/+wtixY7nkkkt49NFHGTRoEFOmTMkYU58+fXjwwQepra3l5ZdfZsqUKSxatIj777+f3/72tzzxxBPU1dWxdu1aAKZOncp1113HmWeeydatW2lsbCztQWqCEoRUNSWI6vP66/lNL8a5555LTU0NABs2bODCCy/k5ZdfxszYsWNHxnXOOOMM9ttvP/bbbz/69OlDQ0MD/fr122uZcePG7Z42cuRIli9fTpcuXTj00EN3tzOYMmUKs2fv+0C7HTt2cMUVV7B48WJqamp46aWXAHjooYf49Kc/TV1dHQA9e/Zk06ZNrFy5kjPPPBMIjd3KSVVMUtVWrQrvq1dDGX9YSRH6989vejE6d+68e/irX/0qJ510Es899xy/+93vsrYJ2G+//XYP19TUsHPnzoKWyea73/0uBxxwAM888wyLFi1q9iJ6JSlBSFWLSxC7dsH69RUNRXI0axZEP5J3q6sL05O0YcMG+vbtC8Bdd91V8u0ffvjhvPrqqyyP7rm+9957s8Zx0EEH0a5dO37605+ya9cuAE499VTuvPNOtkT1b2vXrqVr167069ePefPmAbBt27bd88tBCUKqWurdS6pmqg5Tp8Ls2TBgAJiF99mzS3/9Id0Xv/hFvvSlLzFq1Ki8fvHnqlOnTvzgBz9gwoQJjBkzhq5du9KtW7d9lrv88su5++67GTFiBC+++OLuUs6ECROYNGkSY8eOZeTIkdx8880A/PSnP+XWW2/liCOO4JhjjmFVXGwug1bzTOqxY8e6HhjU9kycCPfdF4YfewyOO66y8bRVS5Ys4f3vf3+lw6i4zZs306VLF9ydz372swwePJirr7660mHtlunvZGZPuXvG+3xVgpCqtmoVHHhgGFYJQirt9ttvZ+TIkQwbNowNGzZwySWXVDqkouguJqlqDQ3wf/5PSBRKEFJpV199dYsqMRRLJQipWu7w9tswbFgYV4IQKS0lCKla69fD9u3hImfXrkoQIqWmBCFVK76Z44ADoL5eCUKk1JQgpGrFt7gqQYgkQwlCqpYShMROOukkHnjggb2m3XLLLVx22WVZ1xk/fjzxrfGnn3466zO0tLzxxht3t0fIZt68ebzwwgu7x6+//noeeuihPKJvuRJNEGY2wcyWmtkyM7suw/zvmtni6PWSma1PmXehmb0cvS5MMk6pTnGCOPBAJYi2bsqUKcydO3evaXPnzs3aYV66BQsW0L1794L2nZ4gZs6cySmnnFLQtlqaxBKEmdUAtwEfAT4ATDGzD6Qu4+5Xu/tIdx8JfA/4TbRuT+AG4ChgHHCDmfVIKlapTqtWQU0N9Oy5J0G0knafkqdzzjmH++67b3e/RsuXL+fNN9/k+OOP57LLLmPs2LEMGzaMG264IeP6AwcOZPXq1QDMmjWLIUOGcNxxx+3uEhxCG4cjjzySESNGcPbZZ7NlyxYef/xx5s+fzzXXXMPIkSN55ZVXmDZtGr/61a8AePjhhxk1ahTDhw/noosuYtu2bbv3d8MNNzB69GiGDx/Oiy++uE9MLaFb8CTbQYwDlrn7qwBmNheYDLyQZfkphKQA8GHgQXdfG637IDAB+HmC8UqVaWiAPn2gXbuQILZvh02bYP/9Kx1Z23bVVRA9u6dkRo6EW27JPr9nz56MGzeO+++/n8mTJzN37lzOO+88zIxZs2bRs2dPdu3axcknn8yzzz7LEUcckXE7Tz31FHPnzmXx4sXs3LmT0aNHM2bMGADOOussLr74YgC+8pWv8OMf/5jPfe5zTJo0iYkTJ3LOOefsta2tW7cybdo0Hn74YYYMGcIFF1zAD3/4Q6666ioAevfuzdNPP80PfvADbr75Zn70ox/ttX5L6BY8ySqmvsAbKeMromn7MLMBwCDgT/msa2bTzWyRmS16R/ULbU5DQ7j+ACFBgKqZ2rLUaqbU6qVf/OIXjB49mlGjRvH888/vVR2U7rHHHuPMM8+krq6O/fffn0mTJu2e99xzz3H88cczfPhw5syZw/PPP99kPEuXLmXQoEEMGTIEgAsvvJBHH3109/yzzjoLgDFjxuzu4C/Vjh07uPjiixk+fDjnnnvu7rhz7Ra8Lr1HxAK0lJbU5wO/cvdd+azk7rOB2RD6YkoiMGm5Ghr2dLORmiAOO6xyMUnTv/STNHnyZK6++mqefvpptmzZwpgxY/jnP//JzTffzMKFC+nRowfTpk3L2s13c6ZNm8a8efMYMWIEd911F4888khR8cZdhmfrLjy1W/DGxsayPwsCki1BrAQOSRnvF03L5Hz2rj7KZ11po1atUglC9ujSpQsnnXQSF1100e7Sw8aNG+ncuTPdunWjoaGB+++/v8ltnHDCCcybN4/33nuPTZs28bvf/W73vE2bNnHQQQexY8cO5qQ8H7Vr165s2rRpn20dfvjhLF++nGXLlgGhV9YTTzwx58/TEroFTzJBLAQGm9kgM+tISALz0xcys6FAD+CvKZMfAE4zsx7RxenTomkiwJ5uNpQgJNWUKVN45plndieIESNGMGrUKIYOHconPvEJjj322CbXHz16NB//+McZMWIEH/nIRzjyyCN3z/va177GUUcdxbHHHsvQoUN3Tz///PP51re+xahRo/a6MFxbW8udd97Jueeey/Dhw2nXrh2XXnppzp+lJXQLnmh332Z2OnALUAPc4e6zzGwmsMjd50fL3AjUuvt1aeteBHw5Gp3l7nc2tS919922rFsX7l769rfh85+Hd9+FLl3gppvg2msrHV3bo+6+q0O+3X0neg3C3RcAC9KmXZ82fmOWde8A7kgsOKlqqW0gADp3hk6dVIIQKSW1pJaqlNoPU0yN5URKSwlCqlJqNxsxJYjKai1Pp2ytCvn7KEFIVVKCaFlqa2tZs2aNkkQL5e6sWbMm71tlW0o7CJG8NDSEbjZ69dozrb4eliypXExtWb9+/VixYgVqsNpy1dbW0q9fv7zWUYKQqrRq1Z5uNmIqQVROhw4dGDRoUKXDkBJTFZNUpdRuNmL19bBlS3iJSPGUIKQqZUsQoFKESKkoQUhVSu2HKaYEIVJaShBSddxVghApByUIqTrr14dnPyhBiCRLCUKqTqY2EKAEIVJqShBSddL7YYrtvz906KAEIVIqShBSdbKVIMzUFkKklJQgpOpk6qgvpgQhUjpKEFJ1MnWzEVOCECkdJQipOg0N+3azEVOCECkdJQipOpnaQMSUIERKRwlCqs6qVU0niI0bYdu28sYk0hopQUjVaa4EAbB6dfniEWmtlCCkqsTdbKS3gYipsZxI6ShBSFXZsCFzNxsxJQiR0lGCkKrSVBsIUIIQKSUlCKkq2VpRx5QgREpHCUKqSrZ+mGI9eoRGdEoQIsVTgpCq0lwJol270MJaCUKkeEoQUlVWrcrezUZMjeVESkMJQqpKQ0NIAJm62YgpQYiUhhKEVJWm2kDElCBESkMJQqpKU62oY0oQIqWhBCFVpal+mGL19bB2LezcWZ6YRForJQipGnE3G7kkCIA1a5KPSaQ1U4KQqhF3s5HLNQhQNZNIsZQgpGo01wYipgQhUhpKEFI1muuHKRYniLffTjYekdZOCUKqhkoQIuWVaIIwswlmttTMlpnZdVmWOc/MXjCz583sZynTd5nZ4ug1P8k4pTo01w9TLG5lrQQhUpz2SW3YzGqA24BTgRXAQjOb7+4vpCwzGPgScKy7rzOzPimbeM/dRyYVn1Sfhobmu9kAaN8eevZUghApVpIliHHAMnd/1d23A3OByWnLXAzc5u7rANxdtcaS1apVzXezEVNjOZHiJZkg+gJvpIyviKalGgIMMbO/mNnfzGxCyrxaM1sUTf9Yph2Y2fRomUXv6GzQ6uXSBiKmBCFSvMSqmPLY/2BgPNAPeNTMhrv7emCAu680s0OBP5nZP9z9ldSV3X02MBtg7NixXtbIpexy6YcpVl8PS5cmG49Ia5dkCWIlcEjKeL9oWqoVwHx33+Hu/wReIiQM3H1l9P4q8AgwKsFYpQqoBCFSXkkmiIXAYDMbZGYdgfOB9LuR5hFKD5hZb0KV06tm1sPM9kuZfizwAtJmuefWD1Osvj50tdHYmGxcIq1ZYgnC3XcCVwAPAEuAX7j782Y208wmRYs9AKwxsxeAPwPXuPsa4P3AIjN7Jpp+U+rdT9L2xN1s5JMgGhtDp30iUphEr0G4+wJgQdq061OGHfh89Epd5nFgeJKxSXXJtQ1ELLWxXO/eycQk0tqpJbVUhVxbUcfUmlqkeEoQUhVy7YcppgQhUjwlCKkKKkGIlJ8ShFSFXLvZiClBiBRPCUKqQkNDOOnX1OS2fMeO0K2bEoRIMZQgpCrk0wYipsZyIsVRgpCqkE8r6pgShEhxlCCkKuTTD1NMCUKkOEoQ0uK5qwQhUglKENLibdgA27YVliBWrw4JRkTy12yCMLOPmpkSiVRMvm0gYvX1sGNHSDAikr9cTvwfB142s2+a2dCkAxJJl28/TDG1hRApTrMJwt0/SXgWwyvAXWb21+hJbl0Tj06E4koQoAQhUqicqo7cfSPwK8JzpQ8CzgSeNrPPJRibCJB/P0wxJQiR4uRyDWKSmf0P4aluHYBx7v4RYATwb8mGJxJKEO3a5d7NRkwJQqQ4uZQgzga+6+7D3f1b7v42gLtvAT6TaHQihATRp0/u3WzElCCaN2cODBwYEvDAgWFcJJbLA4NuBN6KR8ysE3CAuy9394eTCkwkVkgbCIBOnaBzZyWIbObMgenTYcuWMP7aa2EcYOrUysUlLUcuJYhfAqlP9t0VTRMpi0L6YYqpsVx2M2bsSQ6xLVvCdBHILUG0d/ft8Ug03DG5kET2VmgJApQgmvL66/lNl7YnlwTxjplNikfMbDKwOrmQRPaIu9nItw1ETAkiu/7985subU8uCeJS4Mtm9rqZvQFcC1ySbFgiwcaNhXWzEVOCyG7WLKir23taXV2YLgI5XKR291eAo82sSzS+OfGoRCKFNpKLxQnCHcxKF1drEF+InjEjVCv17x+Sgy5QSyyXu5gwszOAYUCtRf9l7j4zwbhEgMIbycXq62HrVnj3XejSpXRxtRZTpyohSHa5NJT7L0J/TJ8DDDgXGJBwXCJA4f0wxdQWQqRwuVyDOMbdLwDWufu/Ax8EhiQblkhQiiomUIIQKUQuCWJr9L7FzA4GdhD6YxJJXKHdbMSUIEQKl8s1iN+ZWXfgW8DTgAO3JxmUSGzVqnCSz7ebjZgShEjhmkwQ0YOCHnb39cCvzez3QK276xEsUhbFtIEAJQiRYjRZxeTujcBtKePblByknIppRQ3hzqX99lOCEClELtcgHjazs810F7mUX7EJwkyN5UQKlUuCuITQOd82M9toZpvMbGPCcYngXlxHfTElCJHC5NKSWo8WlYqIu9ko5hoEKEGIFKrZBGFmJ2Sa7u6Plj4ckT2KbQMRq6+Hl18uPh6RtiaX21yvSRmuBcYBTwEfSiQikUgpE4RKECL5y6WK6aOp42Z2CHBLUgGJxIrthylWXw+bN4c+mWpri49LpK3I5SJ1uhXA+3NZ0MwmmNlSM1tmZtdlWeY8M3vBzJ43s5+lTL/QzF6OXhcWEKdUuWL7YYqpLYRIYXK5BvE9QutpCAllJKFFdXPr1RDaUJxKSCoLzWy+u7+Qssxg4EvAse6+zsz6RNN7AjcAY6N9PxWtuy6PzyZVrthuNmKpCeKQQ4qPS6StyOUaxKKU4Z3Az939LzmsNw5Y5u6vApjZXGAy8ELKMhcDt8Unfnd/O5r+YeBBd18brfsgMAH4eQ77lVaioaG4bjZiKkGIFCaXBPErYKu774JQMjCzOnff0sx6fYE3UsZXAEelLTMk2uZfgBrgRnf/Q5Z1+6bvwMymA9MB+us5ia1OKdpAgBKESKFyakkNdEoZ7wQ8VKL9twcGA+OBKcDtUceAOXH32e4+1t3H1sdnAWk1iu2HKaYEIVKYXBJEbepjRqPhuiaWj60EUmt8+0XTUq0A5rv7Dnf/J/ASIWHksq60csV2sxHr3h3at1eCEMlXLgniXTMbHY+Y2RjgvRzWWwgMNrNBZtYROB+Yn7bMPELpATPrTahyehV4ADjNzHqYWQ/gtGiatBHupUsQZtC7txKESL5yuQZxFfBLM3uT8MjRAwmPIG2Su+80sysIJ/Ya4A53f97MZgKL3H0+exLBC8Au4Bp3XwNgZl8jJBmAmfEFa2kbNm4M7RZKkSBAjeVECpFLQ7mFZjYUODyatNTdd+SycXdfACxIm3Z9yrADn49e6eveAdyRy36k9SlVG4iYEoRI/pqtYjKzzwKd3f05d38O6GJmlycfmrRlpepmI6YEIZK/XK5BXBw9UQ6AqM3CxYlFJIIShEhLkEuCqEl9WFDUQrpjciGJlK4fplh9PaxfDztyqhwVEcgtQfwBuNfMTjazkwmtme9PNixp6+JuNnr3Ls324rYQq1eXZnsibUEudzFdS2itfGk0/izhTiaRxJSqm41YamO5gw4qzTZFWrtmSxDu3gg8ASwn9K/0IWBJsmFJW1eqNhAxtaYWyV/WEoSZDSF0fzEFWA3cC+DuJ5UnNGnLStUPU0wJQiR/TZUgXiSUFia6+3Hu/j1CYzaRxKkEIVJ5TSWIs4C3gD+b2e3RBWprYnmRkoi72ShVIzmAnj1DlxtKECK5y5og3H2eu58PDAX+TOhyo4+Z/dDMTitTfNIGbdpU2m42IFzs7tVLCUIkH7lcpH7X3X8WPZu6H/B3wp1NIokodRuImBrLieQnr2dSu/u66BkMJycVkEg+rajnzIGBA0ObiYEDw3g2ShAi+ckrQYiUQ64d9c2ZA9Onw2uvhesWr70WxrMliUwJIp8EI9LWKEFIi5NrCWLGDNiS9uDbLVvC9Ezq6+Htt/eM55tgRNoaJQhpcVatyq2bjddfz296fT2sXQu7opu1800wIm2NEoS0OA0NITk0181G//75Ta+vDyWFNWvCeL4JRqStUYKQFifXNhCzZkFd2tPR6+rC9EzSG8vlm2BE2holCGlxcm1FPXUqzJ4NAwaERnADBoTxqVMzL5+eIPJNMCJtTS69uYqU1apVMHhwbstOnZo9IaRLTxDxejNmhGql/v1Dcsh1eyKtnRKEtChxNxulbiQHmftjyifBiLQ1qmKSFiXuZqOU/TDF4rui1FhOJDdKENKilPpZ1Kk6dIDu3ZUgRHKlBCEtSlL9MMXU3YZI7pQgpEVJsgQBShAi+VCCkBYl136YCqUEIZI7JQhpURoacutmo1BKECK5U4KQFmXVqty62ShUfT2sXg2NjclsX6Q1UYKQFiWpNhCxPn1CZ33r1ye3D5HWQglCWpRSP4s6XabGciKSmRKEtChJlyCUIERypwQhLUaS3WzElCBEcqcEIS3Gpk3w3ntKECIthRKEtBhJt4EAJQiRfChBSIuRdCtqgP32g65dlSBEcpFogjCzCWa21MyWmdl1GeZPM7N3zGxx9PqXlHm7UqbPTzJOaRnKkSBAjeVEcpXY8yDMrAa4DTgVWAEsNLP57v5C2qL3uvsVGTbxnruPTCo+aXmS7qgvpgQhkpskSxDjgGXu/qq7bwfmApMT3J9Uubibjfg6QVKUIERyk2SC6Au8kTK+IpqW7mwze9bMfmVmh6RMrzWzRWb2NzP7WIJxSgvR0JBsNxsxJQiR3FT6IvXvgIHufgTwIHB3yrwB7j4W+ARwi5kdlr6ymU2Pksiid/QfX/WSbgMRixOEe/L7EqlmSSaIlUBqiaBfNG03d1/j7tui0R8BY1LmrYzeXwUeAUal78DdZ7v7WHcfW590vYQkbtWq8iWI7dtDuwsRyS7JBLEQGGxmg8ysI3A+sNfdSGZ2UMroJGBJNL2Hme0XDfcGjgXSL25LK5N0P0wxtYUQyU1idzG5+04zuwJ4AKgB7nD3581sJrDI3ecDV5rZJGAnsBaYFq3+fuC/zayRkMRuynD3k7Qi5ehmI5aaIA7bp+JSRGKJJQgAd18ALEibdn3K8JeAL2VY73FgeJKxScuyeXPy3WzEVIIQyU2lL1KLAOVrAwFKECK5UoKQFqEc/TDFlCBEcqMEIRU1Zw4MHAjHHx/GFy1Kfp+dO0OnTkoQIs1RgpCKmTMHpk+H117bM+3rXw/Tk6bGciLNU4KQipkxA7Zs2Xvae++F6UlTghBpnhKEVMzrr+c3vZSUIESapwQhFdO/f37TS0kJQqR5ShBSlPgic7t24T2f6wezZkFd3d7T6urC9KQpQYg0TwlCCpZ6kdk9vE+fnnuSmDoVZs+GAQPCeOfOYXzq1ORijtXXh+sf6ddAqk0xCVqkOUoQUrBMF5m3bMnvIvPUqfDPf4bbTi+9tDzJAVpHW4hiE7RUv6R/IChBSMFKdZG5nN1sxFpDgihFgpbKKuYEX44fCEoQUrBSXWQu17OoU7WGBFHJu8AkqOQJvhw/EJQgpGClushczn6YYq0hQVTyLrDWoppP8OX4gaAEIQVLvchsFt4Luchczn6YYq0hQcyaBbW1e08r111gLUVbPsGX5QeCu7eK15gxY1yq0223uYP7W2+Vb5+Nje4dOrhfe2359llqW7e6DxzobhaOX6dO7j/5SaWjKp977nGvqwufPX7V1YXpuRgwYO9149eAAbmtHx/39JdZefZf7OePEZ7Pk/G8qhKEVFxDQyiB9O5dvn2aVX9biOuug+XLYd48uO22cKF/yZLyxlDsXTTFrF/tv+CLraItVQm+SdkyR7W9VIKoXtOnu9fXl3+/I0a4f/Sj5d9vKcyfH34xXnllGG9sdL/kkjBtzpzyxFDsL9hi128Nv+DvuSfszyy85/vrvxRoogRR8RN7qV5KENVr8mT34cPLv99TTnE/+ujy7zdVISeIN95w79XLfdSoUM0U27bN/YQT3Gtr3Z98MqmI9yj2BFvp9VvLCb5YShDSoh19dDhZl9uUKe6HHVb+/cYKOUHt3BmSQOfO7kuX7jv/7bfDiergg93ffDOx0N29+F/wxa6vE3xpNJUgdA2ijat0Vw2NjeE213Le4hqr9DWIQurQv/51ePRR+OEPYciQfefX18P8+bBhA5x5JmzdWtqYUxVbB1/s+qWog586NVzHaWwM7+VqyV8t2lc6AKmc+Da/+CQV3+YHxf+juMOmTbByJbz5Zvb3t96CnTvhvPOK218h6uth40bYtg3226/8+8/3Iun//i/MnAkXXACf+lT27R5xBPzkJ3D22eHveffd4QRaarNm7f39gfwusha7PoTvqU7qyVGCaMOa+gWb6z/d9u1w773w3HN7n/xXroR33913+e7d4eCDoW9fGDo0vPftC+eeW/THyVvcFmL16hBDufXvv/fT9FKnp1u9OvxNDjss3LHUnLPOgn//d7jhBhgxAv7t34qPN138HZkxIyS1/v3DyT3X706x60sZZKt7qraXrkHkr5g64F27wt0yhx4a1unYMdyTf+yx7ued537VVe7f+lZY5pFH3F9+2X3z5uQ/Uz5+/esQ+9//Xvg2iqnDzrUOvbHRfeLEcIyffjr37e/a5X7OOe7t2rkvWJD7etK2oIvUkkkhd4E0Nrr//vfuRxwRlh0xwv2++8L0avPoo+Ez/PGPha1froukt9wStn3rrfnHuHlz+Bvtv7/7kiX5ry+tnxKEZJTvCe6xx9yPOy4sd9hh7j//efiVWq2WLPGi2g0Ue5tlLhYtCi2+J00qPAkvXx7amQwZ4r52belik9ahqQShu5gqrJJ3EeV6F8izz8LEiXD88bBsWbiDZskSOP/8EHe1KrY/pqQ7S9u0KRzjAw6AO+4o/ELzgAHwm9+E525MmRJuChDJSbbMUW2vaixBtPT7uF95xX3q1LDt7t3db7rJ/d13S7f9Stu1y72mxn3GjMLWT7IE0dgYjn27dqEqrBRuvz3E9/nPl2Z70jqgKqaWqSW0BM3krbfcL7/cvX370AHcdde13qqJPn1CVx+FSOr4u7vfdVfY3syZxW8r1ec+F7Z7552l3a5ULyWIFqrSfcmkW7fO/ctfDie59u3dL73UfeXKwrZVLYYNcz/zzMLXT6IE9+KL4W8wfnxoOV1KO3a4n3xyuCPq8cdLu22pTk0lCAvzq9/YsWN90aJFlQ4jLwMHZr4PfsCA0KqzOe3ahZSQziy0DM3Vli3w/e/DTTfBunWhnnrmTHjf+3LfRrU66aRQJ//YY5WOJNi6FY4+OrQjeeaZ0Gak1NasgaOOCo96XbQI+vUr/T6kepjZU+4+NtO8Kr7EWP2K7e630K4K1qyB++8PDalOPz2cIK69NpyYnn4afvaztpEcoPLdbaS75pqQGO66K5nkANCrF/z2t+GHwcc+tm9jSZGYWlIXac6cyrUkzaWrgq1bYfFiePJJeOKJ8HrllTDPDIYNC332XHABnHhibvttTVpSgpg3L5TkPv95OOOMZPc1bFj47k6eDJ/5TPhRkER3HJK7HTvCnWubN2d+b2raYYfBrbeWPiYliCKUoi+jYvqSSU8whxwCV1wBu3aF9yeeCL9Gd+wIy/XtC+PGwcUXhyqGMWOga9fC9t1a1NfD2rWhmql9Bf8bXn8dLroo/E3+8z/Ls8+PfhT+4z/gS18K3aKccQaMHx86AVSyyG7nztCH2BtvhNfrr4eq2W3bCn+99154z4VZ+L/t0iW8d+2aXFcxugZRhGKvIRTr7bf3LhksXAjr14d5XbrAkUeGhHDUUeG9Ev0NtXS33RaSaaV6lIVwwjnxRPjHP0IVXzmr99xDgrj77nAMIByHE0/c8/rAB9pOwnAPVbDxiT/1PR5+883wIyxVTU3o8LHQV13dvif9eDh9Wl1daf8eTV2DUAmiCEk3lEq1ZUs4ecQJ4ckn9yShmhoYPjz0iHrUUeE1dGiYLk1LbSxX7gSxenVohHjPPfD445W59mMWbk74z/+El18OPcbGr1/8IizTuzeccMKehDF8ePkbSO7YEUp6a9aE47Z69Z7hNWvC/0d8H19j477DmaalDq9duycJvPfe3vvu2DFcp+vfP5Sw+vcPpfVDDtkz3K1beY9HuSSaIMxsAvB/gRrgR+5+U9r8acC3gJXRpO+7+4+ieRcCX4mmf93d704y1kLk0xtnPnbtghdf3DsZPPvsnl8tAwaEJHDFFeF99Oh9L3ZLboptTZ2L7dth6dLwN3zmmfD+7LOhmiL22c+Gu8cqxSxULQ0ZEqog3UPL69SE8ZvfhGV79Ait6uOEMXJk5h8ju3aFk+3WreEVD2d637Bh7xN+ehLYsCF77J06QefO4TO0axfeU4czTUsf7tYt9Ho7ceLeJ/7+/cN3pJp7DChGYgnCzGqA24BTgRXAQjOb7+4vpC16r7tfkbZuT+AGYCzgwFPRuuuSircQTV0kbmwMr1279n5lmrZ9e6heiBPCokXh4hOEL+6RR4YH1MdVRZWqCmmNSpkg3KGhYU8CiJPBkiV7rgN17BiqbE49NZyQjjgi/CJvaX9TMzj00PD69KfDtNdf3zthzJ8fpu+/Pxx44L4n/UK69OjcOdxl1bt3eB122J7heHrq/F69QoKQZCRZghgHLHP3VwHMbC4wGUhPEJl8GHjQ3ddG6z4ITAB+XuogV6+GQYMKX7+xMfwzxZdytm6FT34yvPLVvn04aXzqU3uuHQwZ0nZ/vZRDnCDefjv7Mu7hR0B6tUb8/s478NJLISGkJpp+/UICOP308H7EEeHv2aFDsp8pKf37h+9m/LCilSvD0+0efTRc+6qtDSfr2trsw9nmd+sWTva1tRX9iJImyQTRF3gjZXwFcFSG5c42sxOAl4Cr3f2NLOvuc4nVzKYD0wH6F1ivU1u7586jYrRrF4rZqa9cp9XUwOGHw6hR+gcpt169wvvvfx+SRLYk0NSjO3v0CNcOJk3akwiGD9+z7daqb99QLVbJqjFJVqUvUv8O+Lm7bzOzS4C7gQ/lurK7zwZmQ7iLqZAAfvtb+PWv9USrtqp9exg8GB54AP74R+jZc08VxoAB4fpOpmqN+L1Hj8reHiuSpCS/2iuBQ1LG+7HnYjQA7r4mZfRHwDdT1h2ftu4jpQ4wyWcyS/VYvDjUmXfvrju/RFIlWbu9EBhsZoPMrCNwPjA/dQEzOyhldBKwJBp+ADjNzHqYWQ/gtGhaSTX1TGZpO+rqQmlAyUFkb4mVINx9p5ldQTix1wB3uPvzZjaT0HvgfOBKM5sE7ATWAtOiddea2dcISQZgZnzBupTK2Y5BRKTatOmW1JVuCS0iUmnqzTWLYntTFRFpzdp0gsj1mcwiIm1Rm79Br5jeVEVEWrM2XYIQEZHslCBERCQjJQgREclICUJERDJSghARkYxaTUM5M3sHyNDsrcXoDayudBBNUHzFUXzFUXzFKSa+Ae5en2lGq0kQLZ2ZLcrWWrElUHzFUXzFUXzFSSo+VTGJiEhGShAiIpKREkT5zK50AM1QfMVRfMVRfMVJJD5dgxARkYxUghARkYyUIEREJCMliBIxs0PM7M9m9oKZPW9m/5phmfFmtsHMFkev6ysQ53Iz+0e0/32esGTBrWa2zMyeNbPRZYzt8JRjs9jMNprZVWnLlPUYmtkdZva2mT2XMq2nmT1oZi9H7z2yrHthtMzLZnZhGeP7lpm9GP39/sfMumdZt8nvQoLx3WhmK1P+hqdnWXeCmS2NvovXlTG+e1NiW25mi7OsW47jl/G8UrbvoLvrVYIXcBAwOhruCrwEfCBtmfHA7ysc53KgdxPzTwfuBww4GniiQnHWAKsIjXgqdgyBE4DRwHMp074JXBcNXwd8I8N6PYFXo/ce0XCPMsV3GtA+Gv5Gpvhy+S4kGN+NwBdy+Pu/AhwKdASeSf9/Siq+tPnfBq6v4PHLeF4p13dQJYgScfe33P3paHgTsAToW9moCjIZ+IkHfwO6m9lBFYjjZOAVd69o63h3f5TwvPRUk4G7o+G7gY9lWPXDwIPuvtbd1wEPAhPKEZ+7/9Hdd0ajfwP6lXq/ucpy/HIxDljm7q+6+3ZgLuG4l1RT8ZmZAecBPy/1fnPVxHmlLN9BJYgEmNlAYBTwRIbZHzSzZ8zsfjMbVt7IAHDgj2b2lJlNzzC/L/BGyvgKKpPozif7P2alj+EB7v5WNLwKOCDDMi3lOF5EKBFm0tx3IUlXRFVgd2SpHmkJx+94oMHdX84yv6zHL+28UpbvoBJEiZlZF+DXwFXuvjFt9tOEKpMRwPeAeWUOD+A4dx8NfAT4rJmdUIEYmmRmHYFJwC8zzG4Jx3A3D2X5FnmvuJnNAHYCc7IsUqnvwg+Bw4CRwFuEapyWaApNlx7KdvyaOq8k+R1UgighM+tA+CPOcfffpM93943uvjkaXgB0MLPe5YzR3VdG728D/0MoyqdaCRySMt4vmlZOHwGedveG9Bkt4RgCDXG1W/T+doZlKnoczWwaMBGYGp1A9pHDdyER7t7g7rvcvRG4Pct+K3382gNnAfdmW6Zcxy/LeaUs30EliBKJ6it/DCxx9+9kWebAaDnMbBzh+K8pY4ydzaxrPEy4mPlc2mLzgQssOBrYkFKULZesv9wqfQwj84H4jpALgd9mWOYB4DQz6xFVoZwWTUucmU0AvghMcvctWZbJ5buQVHyp17TOzLLfhcBgMxsUlSjPJxz3cjkFeNHdV2SaWa7j18R5pTzfwSSvwLelF3AcoZj3LLA4ep0OXApcGi1zBfA84Y6MvwHHlDnGQ6N9PxPFMSOanhqjAbcR7iD5BzC2zDF2Jpzwu6VMq9gxJCSqt4AdhDrczwC9gIeBl4GHgJ7RsmOBH6WsexGwLHp9uozxLSPUPcffw/+Klj0YWNDUd6FM8f00+m49SzjRHZQeXzR+OuGunVfKGV80/a74O5eybCWOX7bzSlm+g+pqQ0REMlIVk4iIZKQEISIiGSlBiIhIRkoQIiKSkRKEiIhkpAQh0gwz22V79zJbsp5FzWxgak+iIi1J+0oHIFIF3nP3kZUOQqTcVIIQKVD0PIBvRs8EeNLM3hdNH2hmf4o6o3vYzPpH0w+w8HyGZ6LXMdGmaszs9qi//z+aWado+Suj5wA8a2ZzK/QxpQ1TghBpXqe0KqaPp8zb4O7Dge8Dt0TTvgfc7e5HEDrKuzWafivwvx46GhxNaIELMBi4zd2HAeuBs6Pp1wGjou1cmsxHE8lOLalFmmFmm929S4bpy4EPufurUYdqq9y9l5mtJnQfsSOa/pa79zazd4B+7r4tZRsDCX32D47GrwU6uPvXzewPwGZCj7XzPOqkUKRcVIIQKY5nGc7HtpThXey5NngGoV+s0cDCqIdRkbJRghApzsdT3v8aDT9O6H0UYCrwWDT8MHAZgJnVmFm3bBs1s3bAIe7+Z+BaoBuwTylGJEn6RSLSvE6294Pr/+Du8a2uPczsWUIpYEo07XPAnWZ2DfAO8Olo+r8Cs83sM4SSwmWEnkQzqQHuiZKIAbe6+/oSfR6RnOgahEiBomsQY919daVjEUmCqphERCQjlSBERCQjlSBERCQjJQgREclICUJERDJSghARkYyUIEREJKP/DxIhjNvZkR1vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bbd99",
   "metadata": {},
   "source": [
    "$ mkdir -p ~/aiffel/sentiment_classification/data  \n",
    "$ pip list | grep gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2530a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28657d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3680e670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00331888, -0.01792276, -0.00808371, -0.02474831, -0.01509113,\n",
       "        0.04140298,  0.03128812,  0.03959165, -0.01921799, -0.02540353,\n",
       "        0.01312383, -0.00388812,  0.06560034,  0.06210039,  0.0255814 ,\n",
       "        0.03295239], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca4df9",
   "metadata": {},
   "source": [
    "### 워드 임베딩 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a032856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jackson', 0.8793882131576538),\n",
       " ('information', 0.8548316359519958),\n",
       " ('comic', 0.8504863381385803),\n",
       " ('dance', 0.844593346118927),\n",
       " ('squad', 0.8337860703468323),\n",
       " ('book', 0.833193302154541),\n",
       " ('preferred', 0.8286619186401367),\n",
       " ('goals', 0.8267454504966736),\n",
       " ('hughes', 0.8266751170158386),\n",
       " ('prey', 0.8256477117538452)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73500bf",
   "metadata": {},
   "source": [
    "우리가 다룬 정도의 훈련 데이터로는 워드 벡터를 정교하게 학습시키기 어렵습니다.\n",
    "그래서 이번에는 구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 가져다 활용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aeabadfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a31dfb",
   "metadata": {},
   "source": [
    "### 워드 임베딩 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c4316c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf3a0e6",
   "metadata": {},
   "source": [
    "### 임베딩 레이어를 word2vec으로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f17a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07d3d54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49716076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 14s 180ms/step - loss: 0.6966 - accuracy: 0.5159 - val_loss: 0.6877 - val_accuracy: 0.5568\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 4s 144ms/step - loss: 0.6784 - accuracy: 0.5817 - val_loss: 0.6674 - val_accuracy: 0.6121\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 4s 145ms/step - loss: 0.6367 - accuracy: 0.6623 - val_loss: 0.6321 - val_accuracy: 0.6235\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 4s 146ms/step - loss: 0.5251 - accuracy: 0.7813 - val_loss: 0.4559 - val_accuracy: 0.8117\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 4s 145ms/step - loss: 0.3605 - accuracy: 0.8565 - val_loss: 0.3360 - val_accuracy: 0.8602\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 4s 147ms/step - loss: 0.2583 - accuracy: 0.9031 - val_loss: 0.3252 - val_accuracy: 0.8577\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 4s 149ms/step - loss: 0.1994 - accuracy: 0.9283 - val_loss: 0.3021 - val_accuracy: 0.8761\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 4s 148ms/step - loss: 0.1509 - accuracy: 0.9521 - val_loss: 0.3060 - val_accuracy: 0.8778\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 4s 149ms/step - loss: 0.1136 - accuracy: 0.9687 - val_loss: 0.3150 - val_accuracy: 0.8772\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 4s 150ms/step - loss: 0.0875 - accuracy: 0.9795 - val_loss: 0.3258 - val_accuracy: 0.8791\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 5s 151ms/step - loss: 0.0596 - accuracy: 0.9871 - val_loss: 0.3580 - val_accuracy: 0.8693\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.0436 - accuracy: 0.9939 - val_loss: 0.3755 - val_accuracy: 0.8710\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.0292 - accuracy: 0.9970 - val_loss: 0.4062 - val_accuracy: 0.8736\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: 0.4292 - val_accuracy: 0.8728\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0159 - accuracy: 0.9985 - val_loss: 0.4348 - val_accuracy: 0.8729\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0124 - accuracy: 0.9989 - val_loss: 0.4576 - val_accuracy: 0.8723\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0105 - accuracy: 0.9991 - val_loss: 0.4657 - val_accuracy: 0.8723\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.4742 - val_accuracy: 0.8731\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.4887 - val_accuracy: 0.8710\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 4s 150ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.4968 - val_accuracy: 0.8717\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "414377e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5272 - accuracy: 0.8636\n",
      "[0.5272272825241089, 0.8636000156402588]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda9b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
